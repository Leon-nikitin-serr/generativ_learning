{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Автор**: Ермекова Асель\n",
        "\n",
        "В этом домашнем задании вам предстоит реализовать VAE для датасета картинок MNIST.\n",
        "\n",
        "Вы научитесь обучать вариационный автоэнкодер (VAE) генерировать новые изображения с нуля. А также сможете управлять генерацией, указывая желаемый класс объекта, и оценивать качество результата с помощью метрики FID.\n",
        "\n",
        "Это домашнее задание состоит из двух частей:\n",
        "\n",
        "* **I часть.** Реализовать безусловную генерацию картинок при помощи VAE тренированную на датасете MNIST и оценить качество по метрике FID.\n",
        "* **II часть.** Реализовать условную генерацию по классу и оценить качество по метрике FID.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "zPQ-a1t0gOO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установите библиотеку для подсчета FID:"
      ],
      "metadata": {
        "id": "L2D3ZgfKISwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-fid"
      ],
      "metadata": {
        "id": "IhYp4gS8ox32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc279417-be3d-4d7d-857b-ea16cbefcf85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n",
            "Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **I часть. Unconditional VAE (6 баллов)**"
      ],
      "metadata": {
        "id": "gc-Nwikdf1EY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Библиотеки"
      ],
      "metadata": {
        "id": "yG1utf_ZoFXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# Импортните любые необходимые вам библиотеки\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import copy"
      ],
      "metadata": {
        "id": "CCEPzS2qoHhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Датасет."
      ],
      "metadata": {
        "id": "zFU4Gu4vkpf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Скачайте датасет MNIST и подготовьте train dataloader."
      ],
      "metadata": {
        "id": "V3JalSoZqutl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# --- Подготовка данных ---\n",
        "batch_size = 128\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Also define test_dataset here for later use (e.g., FID calculation)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "XauYmn9KtMgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c71482d-7e22-4a79-ce0b-70a30af33c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.35MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 129kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.24MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.46MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 60000\n",
            "Number of test samples: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Для FID сохраните 10k реальных изображений из MNIST test части в папку"
      ],
      "metadata": {
        "id": "d3uNroE4L5Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Для FID сохраните 10k реальных изображений из MNIST test части в папку\n",
        "os.makedirs('mnist_vae_real', exist_ok=True)\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "    img, _ = test_dataset[i]\n",
        "    save_image(img, f'mnist_vae_real/real_{i:05d}.png')"
      ],
      "metadata": {
        "id": "urDPJe8DGqGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Визуализируйте 5 рандомных сэмплов из тренировочных данных и 5 сэмплов из тестовых данных"
      ],
      "metadata": {
        "id": "Z7HWBHlkq4Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "fig, axes = plt.subplots(2, 5, figsize = (12, 5))\n",
        "\n",
        "# Отображение примеров из обучающей выборки\n",
        "for idx in range(5):\n",
        "    sample_idx = random.randint(0, len(train_dataset)-1)\n",
        "    image, target = train_dataset[sample_idx]\n",
        "    axes[0, idx].imshow(image[0], cmap = 'gray')\n",
        "    axes[0, idx].set_title(f'Обучающий пример {idx+1}\\nМетка: {target}')\n",
        "    axes[0, idx].axis('off')\n",
        "\n",
        "# Отображение примеров из тестовой выборки\n",
        "for j in range(5):\n",
        "    sample_idx = random.randint(0, len(test_dataset) - 1)\n",
        "    image, target = test_dataset[sample_idx]\n",
        "    axes[1, j].imshow(image[0], cmap='gray')\n",
        "    axes[1, j].set_title(f'Тестовый пример {j+1}\\nМетка: {target}')\n",
        "    axes[1, j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V_ug8vGxCjET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "82dff53c-af4f-477b-ded2-d5902df9dd08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAHxCAYAAADtDjxuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATndJREFUeJzt3XeYlOXZP+5rYKUToxQBlSJYUGPD2BFExIZEFImgxvZVjBpLEjGiYq8YxURFYxSUYgQN+FoiQl5ir/jaNWJZWySICqKgINy/P/jxyLrLsiy7O1vO8zjmONinzfXMzueZ2Yt75s6llFIAAAAAQETUy3cBAAAAAFQfmkUAAAAAZDSLAAAAAMhoFgEAAACQ0SwCAAAAIKNZBAAAAEBGswgAAACAjGYRAAAAAJm8Nou++eab+Oijj+LLL7/MZxlAGcks1CwyCzWLzELNIrPUZlXeLJo0aVLsvffe0bx582jWrFm0b98+rr766qouo8Z64IEH4qWXXsp+njJlSrz++uv5K4haT2bXjsxS1WR27cgsVU1m147MUtVkdu3IbM2xVs2i119/PY488sjYcMMNo2HDhtGuXbs44ogjVvnL/sMf/hADBw6M5s2bx6233hrTpk2L6dOnx8knn7w2ZdQpr776apx++ukxa9aseOaZZ+Kkk06KBQsW5LusGm/UqFFx2GGHRfv27SOXy8UxxxyT75IqhcxWPZmteB999FFcdNFFsdNOO8V6660XLVu2jJ49e8b06dPzXVqFk9mqJ7MVb9GiRXH88cfH1ltvHeuuu240a9Ystt1227j++utjyZIl+S6vQsls1ZPZyvfEE09ELpeLXC4Xc+fOzXc5FUpmq57MVo4VGf3x7corryz/QVM53XvvvalBgwapTZs26dxzz01//etf03nnnZfatm2bGjRokP7+978X2f5f//pXioh0xRVXlPcuSSnNmTMndenSJUVEioh0yCGH5LukWqFDhw5p/fXXT/vtt18qKChIRx99dL5LqnAymx8yW/H+/Oc/p8aNG6dBgwalG264IY0cOTLtsMMOKSLS7bffnu/yKozM5ofMVrzPP/887bzzzumss85KN954Yxo1alQ66qijUi6XS4MGDcp3eRVGZvNDZivX0qVL03bbbZeaNm2aIiJ99tln+S6pwshsfshs5YiItM8++6SxY8cWub322mvlP2Z5dnrnnXdSkyZN0hZbbJHmzJlTZN1nn32Wtthii9S0adP07rvvZsv79u2bdtttt3IXyg++/fbb9MILL6Q33ngj36XUGoWFhWnZsmUppZSaNm1a65pFMptfMluxXnvttWJvVr/99tu0xRZbpI022ihPVVUsmc0vma0ap556aoqI9Omnn+a7lLUms/kls5Vn1KhRqUWLFun000+vVc0imc0vma14EZFOOeWUij1meXYaMmRIioj02GOPlbj+0UcfTRGRhgwZki1r2bJlOvHEE9Mvf/nLtN5666VGjRqlHXfcMU2ePDnbZsGCBalJkybptNNOK3bMjz76KNWrVy9dfvnlKaWUjj766NShQ4fiJxSRLrjgguznwsLC9Otf/zptttlmqVGjRmn99ddPAwYMSO+//36R/WbMmJEiIs2YMSNb9txzz6XevXunZs2apSZNmqQePXoUO+fRo0eniEjPP/98tuyzzz4rVkdKKR144IHFau7Ro0fq0aNHkWXPPfdc1mkt7dxSSunqq69OEVHsGCVZccySbivX9f7776eISCNGjEjXXnttat++fWrUqFHac88906uvvlrkmCX9Hj788MPUqFGjFBFFHucOHTqkiEinn356sdr69OmTIiIdeOCBRZZ/++23afjw4alz586pQYMGaaONNkpnnXVW+vbbb4ud2ymnnJLGjRuXNttss9SwYcO0ww47pEcffXS1j8uP1cZmkcz+QGZrX2ZX+O1vf5siIn311VflPkZ1IbM/kNnam9lrrrkmRUR68803y32M6kJmfyCztSezn3/+eWrRokW68cYb0wUXXFCrmkUy+wOZrR2ZXbH/woUL06JFi8q0z+oURDncf//90bFjx+jevXuJ6/fcc8/o2LFjPPjgg9myzz//PP7yl79Es2bN4rTTTotWrVrFuHHj4pBDDonx48fHoEGDolmzZtG/f/+4++6749prr4369etn+991112RUoojjjhijWp9/vnn46mnnorDDz88NtpooygsLIxRo0ZFz54944033ogmTZqUuN8777wTPXv2jCZNmsRZZ50VTZo0iVtvvTV69+4d06ZNiz333HON6lgTZ599dpm2mzdvXlxxxRVrdOx99tknfvWrXxVZ9sc//rHEb/C/8847Y8GCBXHKKafEt99+G9dff3306tUrXn311dhggw1WeR/Dhw+Pb7/9tsR1jRo1ivHjx8eIESNinXXWiYiIjz/+OP75z39Go0aNimy7bNmy6NevXzzxxBNx4oknRteuXePVV1+N6667Lt5+++2YMmVKke0fffTRuPvuu+O0006Lhg0bxk033RT77bdfPPfcc7H11luX5eGptWRWZutCZmfPnh1NmjRZ5XOkJpFZma2NmV28eHF89dVXsWjRonjhhRfimmuuiQ4dOkSXLl1Wu291J7MyWxsze/7550ebNm1iyJAhcckll6x2+5pEZmW2NmZ2zJgxcdNNN0VKKbp27RrnnXdeDB48eLX7rdKadpfmzZuXIiL94he/KHW7fv36Ffkf3vj/O37/+te/sm0WLlyYunbtmtq0aZMWL16cUkpp6tSpKSLSP/7xjyLH22abbYp0G4899tjUvn37YvcbP+pWLly4sNg2Tz/9dIqIdOedd2bLftyJPfTQQ1P9+vWLfMZv7ty5qUWLFqlbt27ZsoruxD700EMpItJ+++232k7s0KFDU+vWrVO3bt3K3IktaWjaj+ta0Ylt3Lhx+vjjj7Plzz77bIqIdOaZZ2bLftyJfe2111K9evXS/vvvX2Indp999kktW7ZM99xzT7b8kksuSbvttlvq0KFDkU7s2LFjU7169dLjjz9epN6bb745RUR68skni5xbRKQXXnghW/bBBx+kRo0apf79+6/2sVlZbRtZJLMyW9szm1JKs2bNSo0aNUpHHXXUGu9b3ciszNbWzN51111F/hd4xx13TK+88kqZ9q3OZFZma2NmX3755VS/fv00derUlFKqVSOLZFZma2Nmd9tttzRy5Mh03333pVGjRqWtt946RUS66aabVrvvqqzxbGgrvqm8efPmpW63Yv1XX32VLfv5z38ePXr0yH5u3LhxnHzyyTF79ux48cUXIyKid+/e0a5duxg/fny23WuvvRavvPJKHHnkkdmy1q1bx5w5c2Lx4sWl1tG4cePs30uWLInPP/88unTpEj/96U+z+1zZ/PnzY86cOTFt2rTYd999Y6uttsrWtWjRIo455piYOXNm/Pe//y31fssjpRTnnHNOHHroobHzzjuXuu0nn3wSf/7zn+P888+PZs2aVXgtEREHH3xwbLjhhtnPO+20U+y8887x0EMPrXKfc845J3bYYYc47LDDSlzfoEGDOOKII2L06NHZsjFjxsSxxx5bbNtJkyZF165dY4sttoi5c+dmt169ekVExIwZM4psv+uuu0a3bt2yn9u3bx+/+MUvYurUqbF06dKynXQtJLMyW9szu3DhwjjssMOicePGazfjQzUhszJbWzO71157xbRp02LSpElx0kknxTrrrBPffPPNaver7mRWZmtjZk877bTYf//9o0+fPqVuVxPJrMzWxsw++eSTcfrpp0e/fv3ipJNOipkzZ8bWW28dw4YNi0WLFpW676qscbNoRWhWN71dSSHcYostim3XtWvXiIgoLCxcXlC9enHEEUfElClTYuHChRERMX78+GjUqFGRX9huu+0W3377bZx33nnx8ccfZw/8jy1atCiGDx8eG2+8cTRs2DBatmwZrVq1innz5sX8+fOLbX/wwQfHBhtsEF999VVsvvnmq623Io0fPz5ef/31uPzyy1e77QUXXBDt2rWLIUOGVHgdK2y66abFlm222WarPPcnnngi7r///rjqqqsil8ut8rjHHntsPPzww/Hpp5/Go48+Gp9++mkMHDiw2HazZs2K119/PVq1alXkttlmm0VExJw5c8pU78KFC+Ozzz4r7VRrNZmV2dqc2aVLl8bhhx8eb7zxRtxzzz3Rrl27Mu1XncmszNbWzG6wwQbRu3fvGDBgQIwaNSr69u0b++yzT8yePXu1+1ZnMiuztS2zd999dzz11FPxxz/+cZXb1GQyK7O1LbMladCgQZx66qkxb968mDlz5hrtu8Iaf2fRuuuuG23bto1XXnml1O1eeeWV2HDDDeMnP/lJRBTtiK7Or371qxgxYkRMmTIlBg0aFBMmTIi+ffvGuuuum23Tr1+/OO6442LEiBExYsSIVR7rN7/5TYwePTrOOOOM2HXXXWPdddeNXC4Xhx9+eCxbtqzY9tdcc01suumm8Ytf/KLM9VaExYsXx/nnnx/HH3989uRZlTfffDPGjBkT48aNyz4nWR2cffbZse+++0avXr1izJgxq9xu2223jW233TbuvPPOePPNN+PQQw/NnicrW7ZsWfzsZz+La6+9tsTjbLzxxhVVeq0ms5VDZqtHZk844YR44IEHYvz48dn/0tR0Mls5ZLZ6ZHZlAwYMiHPPPTfuu+++Sv1jobLJbOWQ2fxl9qyzzorDDjssGjRokP1RPW/evIiI+Oijj2Lx4sU1+j9nZLZyyGz1e51dcfwvvviiXPuX6wuu+/btG7feems88cQTscceexRb//jjj0dhYWGRF/5OnTrFv//972LbvvXWWxER0bFjx2zZ1ltvHdtvv32MHz8+Ntpoo/jwww/jz3/+c7F9b7vtthg+fHi8++67WVD22WefItvcc889cfTRRxfpjH/77bfZBe/HunXrFj169IhmzZqVud6KcNNNN8WcOXPiwgsvXO2255xzTmy33Xbxy1/+skJr+LFZs2YVW/b222+XeO5TpkyJp59+usShkCU57rjj4rrrrovZs2fH/fffX+I2nTt3jpdffjn23nvvUju7q6u3SZMm0apVqzLVVVvJrMz+WG3I7FlnnRWjR4+OkSNHxqBBg1Z/EjWIzMrsj9WGzP7YimHxJf3PeE0jszL7YzU5sx999FFMmDAhJkyYUGzdDjvsENtuu2289NJLq73/6kxmZfbHanJmV+W9996LiCj338Jr/DG0iOVv0Bs3bhxDhgyJzz//vMi6L774Ik466aTsW9dXOOCAA+K5556Lp556Klv27bffxqhRo6JNmzZFPpsXEXHUUUfFI488EiNHjowWLVrE/vvvX2ItHTp0iF69ekXv3r2jd+/exdbXr18/ln9f1A/+/Oc/l/qZv1wuF3369ImpU6fGm2++WeTc7rjjjthxxx1L/fb0NbVgwYK47LLL4swzz4w2bdqUuu3TTz8d9913X1x55ZVlesKtjSlTpsQnn3yS/fzcc8/Fs88+W+x3sXTp0hg2bFgMHjw4tttuuzIde/DgwfHJJ59E69ato2fPniVuM3DgwPjkk0/i1ltvLbZu0aJFxb7n4Mfh/uijj+K+++6LPn36FJmJoC6SWZldWW3I7IgRI+Kaa66JYcOGxemnn16mc6hJZFZmV1bTMzt37txiz5GIiL/+9a8REbHjjjuW5ZSqNZmV2ZXV9MxOnjy52G3FH/V33nlnXHfddWU6p+pMZmV2ZTU9syV9RG3BggUxcuTIaNmyZbHnZlmVa2TRpptuGnfccUccccQR8bOf/SyOP/746NSpUxQWFsZtt90Wc+fOjbvuuis6d+6c7TN06NAYP3587L///nHaaadFy5YtY9y4cfHGG2/E+PHjo6CgaCmDBw+OoUOHxuTJk+PXv/51uYen9e3bN8aOHRvrrrtubLnllvH000/H9OnTo0WLFqXud8kll8TUqVOjR48e8Zvf/CabanDevHlxzz33FNv+6aefzj5juuJL0N555514+OGHs20+++yzWLRoUTz88MOx3377ZctffPHFaNmyZQwdOnS15/PII4/EPvvsU+KFpKJ16dIl9thjj/j1r38d3333XXah+3GdH3/8cTRo0KDULwr7sfXWWy8+/fTTqF+//iovEkcddVRMnDgxTjrppJgxY0bsvvvusXTp0njrrbdi4sSJMXXq1CJvMLfeeuvYd999i0w1GBFx0UUXrbae+++/P15++eWIWP7Fca+88kpceumlEbF8iOg222xT5nOrjmRWZldW0zM7efLkGDp0aGy66abRtWvXGDduXJH1++yzT4W+AcoHmZXZldX0zI4bNy5uvvnmOPjgg2OTTTaJBQsWxNSpU2PatGlx0EEH1YqPkMqszK6spmf24IMPLrZsxUii/fffP1q2bFnm86quZFZmV1bTM3vjjTfGlClT4qCDDor27dvHp59+Grfffnt8+OGHMXbs2GjQoEGZz6uIcs+jllJ65ZVX0qBBg1Lbtm3TOuusk9q0aZMGDRqUXn311RK3f/fdd9OAAQPSuuuumxo1apR+/vOfpylTpqzy+AcccECKiPTUU0+Vuab40XR8X375ZTr22GNTy5YtU7NmzdK+++6b3nrrrdShQ4ci06P/eKrBlFKaOXNm6tOnT2rWrFlq0qRJ2nPPPdOjjz5a5P5WTDW4prcVevTokSIiXXfddUWOu2J6yh+fWy6XSzNnziyy/MfTFZb22KzJVIMjRoxIf/zjH9PGG2+cGjZsmLp3755efvnlIvseffTRKSLS6aefXuLj8uOpBleeSvDHSlq/ePHidNVVV6WtttoqNWzYMK233nqpW7du6aKLLkrz588vdm7jxo1Lm266aWrYsGHafvvti/w+S7PiPEq6jR49ukzHqAlkVmZrQ2ZXPNarupU19zWBzMpsbcjs888/nw477LDUvn371LBhw9S0adO0ww47pGuvvTYtWbJktfvXJDIrs7UhsyVZ8fh/9tln5dq/upJZma0NmX3kkUfSPvvsk9q0aZPWWWed9NOf/jT16dMn/fOf/1ztvqVZq2ZRZTv44INT586d811GhVrxxK3OVg5XTbGqCwdVS2bzQ2YpL5nND5mlvGQ2P2SW8pLZ/JDZilGu7yyqCp9++mk8+OCDcdRRR+W7FKAMZBZqFpmFmkVmoWaRWWq6cn1nUWV6//3348knn4y//vWvsc4669ToqVRL0rhx49h3333zXQZUGJmFmkVmoWaRWahZZJbaotqNLHr00UfjqKOOivfffz/uuOOO1X6bek2zwQYbFPmSMKjpZBZqFpmFmkVmoWaRWWqLXEolzGUKAAAAQJ1U7UYWAQAAAJA/mkUAAAAAZDSLAAAAAMhoFpVizJgxkcvlIpfLxRNPPFFsfUopNt5448jlctG3b988VFj5Fi5cGDfeeGP06dMn2rZtG82bN4/tt98+Ro0aFUuXLs13eVCEzC7Xs2fP7HFY+bbffvvluzQoQmYjCgsLS8zritsJJ5yQ7xIhI7PLXX755bHLLrtEq1atolGjRrHpppvGGWecEZ999lm+S4MiZLa4efPmRevWrSOXy8U999yT73KqtYJ8F1ATNGrUKCZMmBB77LFHkeWPPvpofPzxx9GwYcM8VVb53nvvvfjNb34Te++9d/z2t7+Nn/zkJzF16tQ4+eST45lnnok77rgj3yVCMXU5sytstNFGccUVVxRZ1q5duzxVA6Wry5lt1apVjB07ttjyhx9+OMaPHx99+vTJQ1VQurqc2YiImTNnxnbbbReHH354NG/ePN5888249dZb48EHH4yXXnopmjZtmu8SoYi6ntmVDR8+PBYuXJjvMmoEzaIyOOCAA2LSpEnxpz/9KQoKfnjIJkyYEN26dYu5c+fmsbrK1aZNm3j11Vdjq622ypYNGTIkjjvuuBg9enScf/750aVLlzxWCMXV5cyusO6668aRRx6Z7zKgTOpyZps2bVpiVseMGRM/+clP4qCDDspDVVC6upzZiIh777232LJdd901BgwYEPfff38cfvjheagKVq2uZ3aF1157LUaNGhXDhw+P4cOH57ucas/H0Mpg0KBB8fnnn8e0adOyZYsXL4577rknBg8eXOI+y5Yti5EjR8ZWW20VjRo1ig022CCGDBkSX375ZbZNx44dSx163rFjx4j4YYj6mDFjsn0XLFgQ3bp1i06dOsWnn36aLb/mmmtit912ixYtWkTjxo2jW7duJQ6vmzt3brz11lur7aq2bNmySKNohf79+0dExJtvvlnq/pAPdTmzK/v+++/j66+/LvP2kC8yW9Snn34aM2bMiEMOOSQaNWq0xvtDZZPZ4lbUNm/evHLtD5VJZpc7/fTTo3///tG9e/cy71OXaRaVQceOHWPXXXeNu+66K1v2j3/8I+bPn7/K/zkYMmRInHXWWbH77rvH9ddfH8cee2yMHz8+9t1331iyZElERIwcOTLGjh0bY8eOjWHDhkVExLBhw7JlI0eOLPHYS5YsiUMPPTQ+/PDDmDp1arRt2zZbd/3118f2228fF198cVx++eVRUFAQhx12WDz44INFjnHDDTdE165d47nnnivXYzJ79uyIWN5MgupGZiPefvvtaNq0aTRv3jzatGkT559/fnYeUN3IbFF/+9vfYtmyZXHEEUes8b5QFWR2+Xe9zJ07N2bPnh2PP/54nHbaaVG/fv3o2bNnmfaHqiSzEZMmTYqnnnoqrr766jJtT0QkVmn06NEpItLzzz+fbrjhhtS8efO0cOHClFJKhx12WNprr71SSil16NAhHXjggdl+jz/+eIqINH78+CLHe/jhh0tcnlJKM2bMSBGRZsyYUWzd+++/nyIijR49Oi1btiwdccQRqUmTJunZZ58ttu2K+lZYvHhx2nrrrVOvXr2KLL/gggtWeX+r891336Utt9wyderUKS1ZsmSN94fKIrPLHXfccenCCy9M9957b7rzzjtTv379UkSkgQMHrnZfqEoyW7Ju3bqltm3bpqVLl67xvlCZZPYHn376aYqI7LbRRhulu+++u0z7QlWR2R+O2b59+3TOOecUqXXSpEmr3bcuM7KojAYOHBiLFi2KBx54IBYsWBAPPPDAKofsTZo0KdZdd93YZ599Yu7cudmtW7du0axZs5gxY0a56zjrrLNi/PjxMXHixNhpp52KrW/cuHH27y+//DLmz58f3bt3jxdffLHIdhdeeGGklMr1vx+nnnpqvPHGG3HDDTcU+cwrVCd1ObO33XZbXHDBBXHIIYfEUUcdFffdd1+ccMIJMXHixHjmmWfKfS5QmepyZlf29ttvx8yZM+Pwww+PevW8TaP6quuZXX/99WPatGlx//33x8UXXxwtW7b00W+qtbqc2SuvvDKWLFmSjX6ibPylX0atWrWK3r17x4QJE2LhwoWxdOnSGDBgQInbzpo1K+bPnx+tW7cucf2cOXPKVcMtt9yS/aG38mdFV/bAAw/EpZdeGi+99FJ899132fJcLleu+/yxESNGxK233hqXXHJJHHDAARVyTKgMMlvU7373u7j11ltj+vTpscsuu1TosaEiyOxy48ePj4jwETSqvbqe2QYNGkTv3r0jIqJv376x9957x+677x6tW7euM1OQU7PU1cwWFhbGiBEj4sYbb4xmzZqV6xh1lWbRGhg8eHCccMIJMXv27Nh///3jpz/9aYnbLVu2LFq3bp294fuxVq1alev+n3nmmbjsssvi+eefjzPPPDP222+/It8Z9Pjjj0e/fv1izz33jJtuuinatm0b66yzTowePTomTJhQrvtc2ZgxY+Lss8+Ok046Kc4777y1Ph5Utrqe2ZVtvPHGERHxxRdfVOhxoSLJ7PKZaTbffPPo1q1bhRwPKpPM/mC33XaLtm3bxvjx4zWLqLbqYmaHDx8eG264YfTs2TMKCwsj4ofv3/3ss8+isLAw2rdvbzRvCTSL1kD//v1jyJAh8cwzz8Tdd9+9yu06d+4c06dPj913373IMLq1ddxxx8WwYcPiP//5T2y55ZZx5plnxtixY7P19957bzRq1CimTp0aDRs2zJaPHj16re/7vvvui//3//5fHHLIIXHjjTeu9fGgKtTlzP7Ye++9FxHlf3GHqlDXM/vss8/GO++8ExdffHGFHA8qW13P7I99++23MX/+/Eo5NlSEupjZDz/8MN55553YZJNNiq07+eSTI2L5KKdVNc7qMu2zNdCsWbMYNWpUXHjhhXHQQQetcruBAwfG0qVL45JLLim27vvvvy/3lJorpvhr165dXHXVVTFu3Lh45JFHsvX169ePXC4XS5cuzZYVFhbGlClTih1rTaYafOyxx+Lwww+PPffcM8aPH6/rSo1RFzP71VdfFRmyG7F8xpZLL700IiL23Xffcp0LVIW6mNmVrfhf01V9hwRUN3Uxs998802J29x7773x5Zdfxo477liuc4GqUBcze+mll8bkyZOL3Fac19ChQ2Py5MnRtGnTcp1PbWdk0Ro6+uijV7tNjx49YsiQIXHFFVfESy+9FH369Il11lknZs2aFZMmTYrrr79+lZ8PLasTTzwxJkyYECeddFK89tpr0aRJkzjwwAPj2muvjf322y8GDx4cc+bMiRtvvDG6dOkSr7zySpH9b7jhhrjoootixowZpX4p2AcffBD9+vWLXC4XAwYMiEmTJhVZv80228Q222yzVucClamuZfbFF1+MQYMGxaBBg6JLly6xaNGimDx5cjz55JNx4oknxg477LBW5wGVra5ldoWlS5fG3XffHbvsskt07tx5rWqHqlTXMjtr1qzo3bt3/PKXv4wtttgi6tWrFy+88EKMGzcuOnbsGKeffvpanQdUtrqW2T322KPYshWjiH7+85/HwQcfvFbnUZtpFlWSm2++Obp16xa33HJLDBs2LAoKCqJjx45x5JFHxu67777Wx8/lcnHrrbfGtttuG+edd15ce+210atXr7jtttviyiuvjDPOOCM6deoUV111VRQWFhYLV1m9//772XDaU045pdj6Cy64QLOIWqG2ZLZDhw7RvXv3mDx5csyePTvq1asXXbt2jZtvvjlOPPHEtT4PqC5qS2ZXmD59evz3v/+Nc889d61rh+qotmR2o402ikMPPTT+93//N+64445YsmRJdOjQIU499dQ499xzo0WLFmt9LlAd1JbMUn65lFLKdxEAAAAAVA++fAYAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMhoFgEAAACQ0SwCAAAAIFNQ1g1zuVxl1gE1Skop3yWslszCD2QWahaZhZpFZqFmKUtmjSwCAAAAIKNZBAAAAEBGswgAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMhoFgEAAACQ0SwCAAAAIKNZBAAAAEBGswgAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMhoFgEAAACQ0SwCAAAAIKNZBAAAAEBGswgAAACATEG+C6BqpJQq/Ji5XK7CjwkAAADkl5FFAAAAAGQ0iwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgExBvgtgzaSU8l1CprRacrlcFVYCAAAAVBQjiwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgIxmEQAAAACZgnwXQHGlTUlfU5R2DrlcrgorAQAAANaEkUUAAAAAZDSLAAAAAMhoFgEAAACQ0SwCAAAAIKNZBAAAAEBGswgAAACATEG+CyD/SpvKPqVUhZUAAED1VdXvjUt7nw41UWkZqg3P98q4RuTrcTGyCAAAAICMZhEAAAAAGc0iAAAAADKaRQAAAABkNIsAAAAAyGgWAQAAAJApyHcBdVVNmXaztP2q+hyAylNT8lwbplSFlZU3e7IAq1dTXttKU9unGad2qg3ZK01tP78VjCwCAAAAIKNZBAAAAEBGswgAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZAryXQAVx/SZUDfUlek6obaojMyaTpu6xOseVD+1PZdVfX7V8bXbyCIAAAAAMppFAAAAAGQ0iwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABApiDfBbBmquOUelDdlHeqy+qUr+o0HWl1elyo3mpD9sqrOmUWaiIZAmq7mvZ+x8giAAAAADKaRQAAAABkNIsAAAAAyGgWAQAAAJDRLAIAAAAgo1kEAAAAQKYg3wXUVTVt2jyobmrKFN3VaSpg1x2qK3lec/IMa6e8Garq64Csk0+V8XyvTs/p2n5+a8vIIgAAAAAymkUAAAAAZDSLAAAAAMhoFgEAAACQ0SwCAAAAIKNZBAAAAECmIN8FUL1Vp2mCoboy7SYsV9rztjJy4jUKao+qft1z/YDlavv72Np+fpXJyCIAAAAAMppFAAAAAGQ0iwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABApiDfBVA71ZXpBKlc1Wla2+pUC9RE5X1dqA3Z85oIq1cbsl4a1wHyqbZPH1/bzy9fjCwCAAAAIKNZBAAAAEBGswgAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZAryXQD5V9unKoWV1ZTne2l1msqTuqSqn+/lvUbIJaxeTXkNLi/XAfKptuerqnk/YGQRAAAAACvRLAIAAAAgo1kEAAAAQEazCAAAAICMZhEAAAAAGc0iAAAAADIF+S6gNqvt0xfWpmkBqZ5Ke45Vp3xVdZ2lHVMuASA/vD5T2ar6/W95n7fV6X16VatN1wEjiwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgIxmEQAAAACZgnwXUBPU5an/oLqqKVNPmnIUAJarKa/dlfEaXJum06ZyVaf3gNWpluqkrmTWyCIAAAAAMppFAAAAAGQ0iwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABApiDfBVQXVT0tYGnT7VWnKQrryrSAAADVWXnfH3ovt+Zqyvt0YDnXucphZBEAAAAAGc0iAAAAADKaRQAAAABkNIsAAAAAyGgWAQAAAJDRLAIAAAAgU5DvAqpSZUx1aZo+WDul5VK+AGDt1OXX2eo0zX1tf6ypOKU9V2pKnv3dXTsYWQQAAABARrMIAAAAgIxmEQAAAAAZzSIAAAAAMppFAAAAAGQ0iwAAAADIFOS7gNqsOk3XWV7V6RxMl1j3lPf5V1OeK9UpX1CXyB4sJwtQs9SU97jUDkYWAQAAAJDRLAIAAAAgo1kEAAAAQEazCAAAAICMZhEAAAAAGc0iAAAAADIF+S6gpqvqKUfLO11iTZka1XSQdU9pv/PyPm9L289zDIDqqqa8X6vLvI8A6gojiwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgIxmEQAAAACZgnwXQHGVMSVnZUxPbupQKltlPG9L268yntOVMQ2y7MHaqYxrC1SE8l7fPW8rltdZWD3vcWs/I4sAAAAAyGgWAQAAAJDRLAIAAAAgo1kEAAAAQEazCAAAAICMZhEAAAAAmYJ8F1Cb1ZSp/2pKnbCyypj6ujpNPSyXAJRVZbwmVideEyE/KuP6Ic81h5FFAAAAAGQ0iwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgExBvguo6Uz9B9VPTZlC2PUDgMrmtQaA8jCyCAAAAICMZhEAAAAAGc0iAAAAADKaRQAAAABkNIsAAAAAyGgWAQAAAJApyHcBVcnUoYDrAAAALJdSqvBjer9dOxhZBAAAAEBGswgAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMgU5LsAAAAAoHKklCr8mLlcrsKPSfViZBEAAAAAGc0iAAAAADKaRQAAAABkNIsAAAAAyGgWAQAAAJDRLAIAAAAgo1kEAAAAQEazCAAAAICMZhEAAAAAGc0iAAAAADKaRQAAAABkNIsAAAAAyGgWAQAAAJApyHcBAAAAQOXI5XL5LoEayMgiAAAAADKaRQAAAABkNIsAAAAAyGgWAQAAAJDRLAIAAAAgo1kEAAAAQKYg3wUAAFQXphcGADCyCAAAAICVaBYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgIxmEQAAAACZXEop5bsIAAAAAKoHI4uqiXHjxkVhYWH285gxY+KTTz7JX0FAqWQWahaZhZpFZqFmkdnap1KbRblcrky3f/3rX5VZRo3w+OOPx9ChQ6OwsDCmTp0ap5xyStSrp5e3ti677LLo169fbLDBBpHL5eLCCy/Md0nVmsyWncxWvLfeeiuGDh0a2223XTRv3jzatm0bBx54YLzwwgv5Lq3aktmyk9mK95///CeOPPLI2HzzzaN58+bx05/+NHbaaae44447wsD1ksls2cls5Rs/fnzkcrlo1qxZvkuptmS27GS24hUWFq7yOfe3v/2t0u+/oDIPPnbs2CI/33nnnTFt2rRiy7t27VqZZdQIZ555ZvTs2TM6deoUERG//e1vo23btnmuquY777zzok2bNrH99tvH1KlT811OtSezZSezFe+vf/1r3HbbbXHooYfGySefHPPnz49bbrkldtlll3j44Yejd+/e+S6x2pHZspPZijd37tz4+OOPY8CAAdG+fftYsmRJTJs2LY455pj497//HZdffnm+S6x2ZLbsZLZyff311zF06NBo2rRpvkup1mS27GS28gwaNCgOOOCAIst23XXXSr/fKv3OolNPPTVuvPFG/9u0Ct9880289tpr0bJly+jcuXO+y6kVCgsLo2PHjjF37txo1apVXHDBBUYXrQGZLZ3MVqyZM2fG5ptvXuR/OD///PPo2rVrbLbZZvHEE0/ksbqaQWZLJ7NV46CDDooZM2bE/Pnzo379+vkup1qT2dLJbOX5wx/+EFOmTIkdd9wxpkyZEl9//XW+S6oRZLZ0MluxCgsLo1OnTjFixIj4/e9/X+X3X63GhX333XdxwQUXRJcuXaJhw4ax8cYbx9ChQ+O7774rtu24ceNip512iiZNmsR6660Xe+65ZzzyyCMREdGxY8dShwl27NgxO84333wTv/vd72LjjTeOhg0bxuabbx7XXHNNsQvAyvvXr18/NtxwwzjxxBNj3rx52Tb/+te/IpfLxT333LPKczzmmGOK3P+KoWVjxoyJpk2bxs477xydO3eOU045JXK5XBxzzDGlPmalDU3L5XLRs2fPYvXdfffdMWzYsGjTpk00bdo0+vXrFx999FGR4/bs2bPIvhERzz//fHbckh6bkSNHFqtviy22iFwuF6eeemqR5fPmzYszzjgje9y7dOkSV111VSxbtqzYuV1zzTVx3XXXRYcOHaJx48bRo0ePeO2110p9XFZY+bGm4smszFZkZrt161ZsKHyLFi2ie/fu8eabb652f1ZPZmW2ol9nS9KxY8dYuHBhLF68uNzHYDmZldnKyOysWbPiuuuui2uvvTYKCir1gyZ1jszKbGW9zn7zzTdV/rpaba4Oy5Yti379+sUTTzwRJ554YnTt2jVeffXVuO666+Ltt9+OKVOmZNtedNFFceGFF8Zuu+0WF198cTRo0CCeffbZ+N///d/o06dPjBw5MuuOv/nmm3H55ZfHsGHDsuGBK/4YSSlFv379YsaMGXH88cfHdtttF1OnTo2zzjorPvnkk7juuuuK1Ni/f/845JBD4vvvv4+nn346/vKXv8SiRYuKDUNcW++8807ceuuta7RPSUPTzjnnnBK3veyyyyKXy8XZZ58dc+bMiZEjR0bv3r3jpZdeisaNG6/yPs4+++xVrmvUqFGMHj06zjjjjGzZU089FR988EGxbRcuXBg9evSITz75JIYMGRLt27ePp556Ks4555z49NNPi4X0zjvvjAULFsQpp5wS3377bVx//fXRq1evePXVV2ODDTZYZU1ULpn9gcyOLLJ9RWd29uzZ0bJlyzXej6Jk9gcyO7LI9mub2UWLFsU333wTX3/9dTz66KMxevTo2HXXXUs9V1ZPZn8gsyOLbL+2mT3jjDNir732igMOOCAmTpy42u0pG5n9gcyOLLL92mb2oosuirPOOityuVx069YtLrvssujTp89q91trqQqdcsopaVV3OXbs2FSvXr30+OOPF1l+8803p4hITz75ZEoppVmzZqV69eql/v37p6VLlxbZdtmyZcWOO2PGjBQRacaMGcXWTZkyJUVEuvTSS4ssHzBgQMrlcumdd97JlkVEuuCCC4pst9tuu6Utt9yy2H1NmjSpxHNMKaWjjz46dejQIfv5/fffTxGRRo8enS0bOHBg2nrrrdPGG2+cjj766FUea+X9R4wYUWzdVlttlXr06FGsvg033DB99dVX2fKJEyemiEjXX399tqxHjx5F9n3ooYdSRKT99tuv2O8wItKAAQNSQUFBeuGFF7Llxx9/fBo8eHCKiHTKKadkyy+55JLUtGnT9Pbbbxc5zh/+8IdUv3799OGHHxY5t8aNG6ePP/442+7ZZ59NEZHOPPPMUh+blX322Wcl/g4pnczKbEr5yewKjz32WMrlcun8889f433rIpmV2ZSqPrNXXHFFiojstvfee2f3QelkVmZTqtrMPvDAA6mgoCC9/vrrKaXlj3/Tpk1Xux/LyazMplR1mf3ggw9Snz590qhRo9L//M//pJEjR6b27dunevXqpQceeKDUfStCtfkY2qRJk6Jr166xxRZbxNy5c7Nbr169IiJixowZERExZcqUWLZsWQwfPrzYt6v/eDjZ6jz00ENRv379OO2004os/93vfhcppfjHP/5RZPnChQtj7ty5MXv27Lj33nvj5Zdfjr333rvYcRcsWBBz584tMqSvrGbOnBmTJk2KK664otK+Pf5Xv/pVNG/ePPt5wIAB0bZt23jooYdK3D6lFOecc04ceuihsfPOO5e4zQYbbBAHHnhgjB49OiKWP1YTJ06MY489tti2kyZNiu7du8d6661X5Hfdu3fvWLp0aTz22GNFtj/44INjww03zH7eaaedYuedd15lvVQNmV1OZisvs3PmzInBgwdHp06dYujQoWu0L8XJ7HIyW/GZHTRoUEybNi0mTJgQgwcPjojlo41YOzK7nMxWXGYXL14cZ555Zpx00kmx5ZZblrota05ml5PZists+/btY+rUqXHSSSfFQQcdFKeffnr83//9X7Rq1Sp+97vflbpvRag2zaJZs2bF66+/Hq1atSpy22yzzSJi+R8NERHvvvtu1KtXr0IucB988EG0a9euyBMt4odvs//xkLMRI0ZEq1atom3btjFgwIDo3r17XHXVVcWOe9xxx0WrVq1ivfXWi+bNm8fgwYPjv//9b5lq+sMf/hDdu3ePvn37lvOsVm/TTTct8nMul4suXbpEYWFhiduPHz8+Xn/99dXOanLsscfGhAkT4rvvvotJkybFeuutl10cVzZr1qx4+OGHi/2uV8x0tOJ3vap6IyI222yzVdZL1ZDZ5WS2cjL7zTffRN++fWPBggVx3333mda3AsjscjJb8Znt0KFD9O7dOwYNGhTjx4+PTTbZJHr37q1htJZkdjmZrbjMXnfddTF37ty46KKLSt2O8pHZ5WS2cv+eXX/99ePYY4+Nf//73/Hxxx+v8f5rolp9Z9HPfvazuPbaa0tcv/HGG1dxRcUdddRR8atf/SqWLVsW7733XlxyySXRt2/fmD59epEu8PDhw6N79+6xZMmSmDlzZlx88cUxb9681XYOH3nkkZg+fXo8/fTTlX0qZbZ48eI4//zz4/jjj88udKty4IEHRoMGDWLKlCkxevToOProo0vsJi9btiz22WefVY4UWN39UD3IrMyuUNGZXbx4cRxyyCHxyiuvxNSpU2Prrbeu0OPXVTIrsytU9uvsgAED4tZbb43HHnss9t1330q9r9pMZmV2hYrI7Pz58+PSSy+Nk08+Ob766qv46quvIiLi66+/jpRSFBYWRpMmTaJ169ZrfV91lczK7AqV/Tq74rn0xRdfxEYbbVRp91NtmkWdO3fOhsGVNvyuc+fOsWzZsnjjjTdiu+22W6v77NChQ0yfPj0WLFhQpBv71ltvZetXtuJ/ylZYd911Y/DgwfHMM8/Errvumi3/2c9+lm23//77x4cffhh33HFHfP/996usJaUUf/jDH6J///6xyy67rNV5rc6sWbOK3fc777wT22yzTbFtb7rpppgzZ06ZppsvKCiIo446Ki677LJ4/fXX4/bbby9xu86dO8fXX39d5LFck3ojIt5++20zneWZzMpsWeuNKHtmly1bFr/61a/in//8Z0ycODF69OhRpvtk9WRWZstab8Tavc6uGFE0f/78cu3PcjIrs2WtN2L1mf3yyy/j66+/jquvvjquvvrqYus7deoUv/jFL4p8CTNrRmZltqz1Rqzd6+x7770XERGtWrUq1/5lVW0+hjZw4MD45JNPSvzW9BWzbEQs/7xfvXr14uKLLy4yLV1EFJsecHUOOOCAWLp0adxwww1Fll933XWRy+Vi//33L3X/FW+GSpoKcWXLli2LevXqlXrR+Nvf/havvPJKXHHFFWWsvvxWfBv7Cvfcc098+umnxc53wYIFcdlll8WZZ54Zbdq0KdOxjzvuuHj11Vdjzz33jE022aTEbQYOHBhPP/10TJ06tdi6efPmFbsITZkyJT755JPs5+eeey6effbZ1f5+qFwyK7MRFZ/Z3/zmN3H33XfHTTfdFIccckiZzoGykVmZjajYzH722WclLr/tttsil8vFDjvssLrToRQyK7MRFZfZ1q1bx+TJk4vd9tprr2jUqFFMnjx5lTNPUTYyK7MRlf86+8knn8Ttt98e22yzTbRt27Ysp1Ru1WZk0VFHHRUTJ06Mk046KWbMmBG77757LF26NN56662YOHFiTJ06NXbcccfo0qVLnHvuuXHJJZdE9+7d45BDDomGDRvG888/H+3atVujJ+dBBx0Ue+21V5x77rlRWFgY2267bTzyyCNx3333xRlnnBGdO3cusv0rr7wS48aNi5RSvPvuu/GnP/0pNtpoo9hxxx2LbPfSSy9Fs2bN4vvvv4+ZM2fGnXfeGb/4xS+ifv36q6zlkUceiRNOOCE233zzNXvgymH99dePPfbYI4499tj473//GyNHjowuXbrECSecUGS7F198MVq2bLlGXyzbtWvXmDt3bqlTFp511lnxP//zP9G3b9845phjolu3bvHNN9/Eq6++Gvfcc08UFhYWmSa7S5cusccee8Svf/3r+O6772LkyJHRokWLMtU1duzY+OCDD2LhwoUREfHYY4/FpZdeGhHLn3M/7rZTdjIrsxWd2ZEjR8ZNN90Uu+66azRp0iTGjRtXZH3//v2jadOmZT43ipJZma3ozF522WXx5JNPxn777Rft27ePL774Iu699954/vnn4ze/+U106dKlzOdFcTIrsxWZ2SZNmsTBBx9cbPmUKVPiueeeK3Eda0ZmZbaiX2eHDh0a7777buy9997Rrl27KCwsjFtuuSW++eabuP7668t8TuVW6fOtraS0qQZTSmnx4sXpqquuSltttVVq2LBhWm+99VK3bt3SRRddlObPn19k29tvvz1tv/322XY9evRI06ZNK3bM0qYaTCmlBQsWpDPPPDO1a9curbPOOmnTTTdNI0aMKDZtYaw0JWwul0tt2rRJhxxySHrzzTeL3deKW0FBQerQoUM67bTT0pdffplSWvVUg40bN06ffPJJkfvs0KFDpUw1eNddd6VzzjkntW7dOjVu3DgdeOCB6YMPPiiyb48ePVJEpOuuu67I8gsuuKDEqQZXnkrwx0pav2DBgnTOOeekLl26pAYNGqSWLVum3XbbLV1zzTVp8eLFxc7tj3/8Y9p4441Tw4YNU/fu3dPLL79c6uPy4/Mo6baq5wQ/kFmZXaEqMnv00UevMq8Rkd5///3VHqOuk1mZXaEqMvvII4+kvn37Zr/b5s2bp9133z2NHj26xOmfKU5mZXaFqnpv/GNHH310atq0abn2rYtkVmZXqIrMTpgwIe25556pVatWqaCgILVs2TL1798/zZw5c7X7VoRcSms41o0a61//+lfstddeMWnSpBgwYEC+y1mtwsLC6NSpU4wYMSJ+//vf57scqHIyCzWLzELNIrNQs8hs1ao231kEAAAAQP5pFgEAAACQ0SwCAAAAIOM7iwAAAADIGFkEAAAAQEazCAAAAICMZhEAAAAAGc2iUowZMyZyuVzkcrl44okniq1PKcXGG28cuVwu+vbtm4cKq968efOidevWkcvl4p577sl3OVCEzC7Xs2fP7HFY+bbffvvluzQoQmZ/sHjx4rj88stjiy22iEaNGsUGG2wQBx54YHz88cf5Lg0yMrvckiVL4qKLLopNNtkkGjZsGJtssklceuml8f333+e7NChCZpeT2fIpyHcBNUGjRo1iwoQJscceexRZ/uijj8bHH38cDRs2zFNlVW/48OGxcOHCfJcBpZLZiI022iiuuOKKIsvatWuXp2qgdHU9s0uWLIkDDzwwnnrqqTjhhBNim222iS+//DKeffbZmD9/fmy00Ub5LhGKqOuZPfLII2PSpElx3HHHxY477hjPPPNMnH/++fHhhx/GX/7yl3yXB8XIrMyWh2ZRGRxwwAExadKk+NOf/hQFBT88ZBMmTIhu3brF3Llz81hd1Xnttddi1KhRMXz48Bg+fHi+y4FVktmIddddN4488sh8lwFlUtcze91118Wjjz4aTzzxROy00075LgdWqy5n9vnnn4+JEyfG+eefHxdffHFERJx00knRsmXLuPbaa+PUU0+NbbbZJs9VQlEyK7Pl4WNoZTBo0KD4/PPPY9q0admyxYsXxz333BODBw8ucZ9ly5bFyJEjY6uttsqGkw8ZMiS+/PLLbJuOHTuW+FGRFbeOHTtGRERhYWHkcrkYM2ZMtu+CBQuiW7du0alTp/j000+z5ddcc03stttu0aJFi2jcuHF069atxI+LzZ07N9566601GiV0+umnR//+/aN79+5l3gfyQWaX+/777+Prr78u8/aQL3U5s8uWLYvrr78++vfvHzvttFN8//33RvBS7dXlzD7++OMREXH44YcXWX744YdHSinuvvvuUveHfJBZmS0PzaIy6NixY+y6665x1113Zcv+8Y9/xPz584s96VYYMmRInHXWWbH77rvH9ddfH8cee2yMHz8+9t1331iyZElERIwcOTLGjh0bY8eOjWHDhkVExLBhw7JlI0eOLPHYS5YsiUMPPTQ+/PDDmDp1arRt2zZbd/3118f2228fF198cVx++eVRUFAQhx12WDz44INFjnHDDTdE165d47nnnivTYzBp0qR46qmn4uqrry7T9pBPMhvx9ttvR9OmTaN58+bRpk2bOP/887PzgOqmLmf2jTfeiP/85z+xzTbbxIknnhhNmzaNpk2bxjbbbBMzZsxY7WMH+VCXM/vdd99FRETjxo2LLG/SpElERMycObPU/SEfZFZmyyWxSqNHj04RkZ5//vl0ww03pObNm6eFCxemlFI67LDD0l577ZVSSqlDhw7pwAMPzPZ7/PHHU0Sk8ePHFzneww8/XOLylFKaMWNGiog0Y8aMYuvef//9FBFp9OjRadmyZemII45ITZo0Sc8++2yxbVfUt8LixYvT1ltvnXr16lVk+QUXXLDK+yvpmO3bt0/nnHNOkVonTZq02n2hKsnscscdd1y68MIL07333pvuvPPO1K9fvxQRaeDAgavdF6qSzKb097//PUVEatGiRdp0003T6NGj0+jRo9Omm26aGjRokF5++eVS94eqJLMp3XvvvSki0tixY4ssv/nmm1NEpK233rrU/aEqyazMrg0ji8po4MCBsWjRonjggQdiwYIF8cADD6xyyN6kSZNi3XXXjX322Sfmzp2b3bp16xbNmjVbq/8pPOuss2L8+PExceLEEr/XYOWO6Zdffhnz58+P7t27x4svvlhkuwsvvDBSStGzZ8/V3ueVV14ZS5YsybrFUBPU5czedtttccEFF8QhhxwSRx11VNx3331xwgknxMSJE+OZZ54p97lAZaqrmV3xUdEFCxbEP//5zzjmmGPimGOOienTp0dKyYheqq26mtkDDjggOnToEL///e/j73//e3zwwQcxceLEOPfcc6OgoCAWLVpU7nOByiSzMrumfMF1GbVq1Sp69+4dEyZMiIULF8bSpUtjwIABJW47a9asmD9/frRu3brE9XPmzClXDbfcckv2h97KnxVd2QMPPBCXXnppvPTSS9mQu4iIXC5XrvssLCyMESNGxI033hjNmjUr1zEgH+pqZlfld7/7Xdx6660xffr02GWXXSr02FAR6mpmV7wp3n333WPjjTfOlrdv3z722GOPeOqpp8p1XKhsdTWzjRo1igcffDAGDhwYhx56aERENGzYMK6++uq47LLLvF+m2pJZmV1TmkVrYPDgwXHCCSfE7NmzY//994+f/vSnJW63bNmyaN26dYwfP77E9a1atSrX/T/zzDNx2WWXxfPPPx9nnnlm7LffftGyZcts/eOPPx79+vWLPffcM2666aZo27ZtrLPOOjF69OiYMGFCue5z+PDhseGGG0bPnj2jsLAwIiJmz54dERGfffZZFBYWRvv27aNePYPUqH7qYmZXZcUfoV988UWFHhcqUl3MbLt27SIiYoMNNii2rnXr1vF///d/5TouVIW6mNmIiK222ipee+21eOONN+LLL7+MLbfcMho3bhxnnnlm9OjRo9zHhcomszK7JjSL1kD//v1jyJAh8cwzz5T6remdO3eO6dOnx+67717si7TWxnHHHRfDhg2L//znP7HlllvGmWeeGWPHjs3W33vvvdGoUaOYOnVqNGzYMFs+evToct/nhx9+GO+8805ssskmxdadfPLJEbG8K7yqCw3kU13M7Kq89957EVH+F3eoCnUxsz/72c9inXXWiU8++aTYuv/85z8yS7VWFzO7Qi6Xi6222ir7+aGHHoply5ZF79691/rYUFlkVmbXhOEga6BZs2YxatSouPDCC+Oggw5a5XYDBw6MpUuXxiWXXFJs3ffffx/z5s0r1/2vmLK+Xbt2cdVVV8W4cePikUceydbXr18/crlcLF26NFtWWFgYU6ZMKXassk41eOmll8bkyZOL3Fac19ChQ2Py5MnRtGnTcp0PVLa6mNmvvvqqyJDdiIiUUlx66aUREbHvvvuW61ygKtTFzDZv3jwOOOCAeOqpp+Ktt97Klr/55pvx1FNPxT777FOuc4GqUBczW5JFixbF+eefH23bto1Bgwat+YlAFZHZ5WS2bIwsWkNHH330arfp0aNHDBkyJK644op46aWXok+fPrHOOuvErFmzYtKkSXH99dev8vOhZXXiiSfGhAkT4qSTTorXXnstmjRpEgceeGBce+21sd9++8XgwYNjzpw5ceONN0aXLl3ilVdeKbL/DTfcEBdddFHMmDGj1C8F22OPPYotWzGK6Oc//3kcfPDBa3UeUNnqWmZffPHFGDRoUAwaNCi6dOkSixYtismTJ8eTTz4ZJ554Yuywww5rdR5Q2epaZiMiLr/88vjnP/8ZvXr1itNOOy0iIv70pz/F+uuvb3IJqr26mNmBAwdGu3btYsstt4yvvvoqbr/99njvvffiwQcfjObNm6/VeUBlk1mZLSvNokpy8803R7du3eKWW26JYcOGRUFBQXTs2DGOPPLI2H333df6+LlcLm699dbYdttt47zzzotrr702evXqFbfddltceeWVccYZZ0SnTp3iqquuisLCwmLhAoqqLZnt0KFDdO/ePSZPnhyzZ8+OevXqRdeuXePmm2+OE088ca3PA6qL2pLZiIgtt9wyHn300Tj77LPj0ksvjXr16kWvXr1ixIgRseGGG671uUB1UJsyu+OOO8bo0aPjlltuicaNG0f37t1jwoQJsd122631eUB1IbPkUkop30UAAAAAUD34ziIAAAAAMppFAAAAAGQ0iwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgExBWTfM5XKVWQfUKCmlfJewWjILP5BZqFlkFmoWmYWapSyZNbIIAAAAgIxmEQAAAAAZzSIAAAAAMppFAAAAAGQ0iwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgIxmEQAAAAAZzSIAAAAAMppFAAAAAGQK8l0AAFC3pZTKtV8ul6vgSgAAiDCyCAAAAICVaBYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgIxmEQAAAACZgnwXAADUfimlfJcAAEAZGVkEAAAAQEazCAAAAICMZhEAAAAAGc0iAAAAADKaRQAAAABkNIsAAAAAyBTkuwBqp/JOkZzL5Sq4EgAAAGBNGFkEAAAAQEazCAAAAICMZhEAAAAAGc0iAAAAADKaRQAAAABkNIsAAAAAyBTku4DarLZPH1/bzw/ySb4AAIB8MbIIAAAAgIxmEQAAAAAZzSIAAAAAMppFAAAAAGQ0iwAAAADIaBYBAAAAkCnIdwEANV15p7kvr1wuV6X3BwAAlc176urFyCIAAAAAMppFAAAAAGQ0iwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABApiDfBdR05Z3er6ZM01fV0xdCRagNz9uaco2AldWG7AGVp6ZcI7wGw+rVlDyXprRzcB0wsggAAACAlWgWAQAAAJDRLAIAAAAgo1kEAAAAQEazCAAAAICMZhEAAAAAmYJ8F1AT1IZpAauaqQapbOXNpecm1CwyC9VPbX9vbDptWK46Zb282SvvObgOGFkEAAAAwEo0iwAAAADIaBYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgExBvguoLipjWsC6MqUeAAA1T3WaFrumMJ02tU1VXweqOiel3Z9rYOmMLAIAAAAgo1kEAAAAQEazCAAAAICMZhEAAAAAGc0iAAAAADKaRQAAAABkCvJdAPlnykAAqqvKmKa6Lr/umdqbylYbnmPlvUZUxvUKKkJVv+7V9ud7eR/Pmva4GFkEAAAAQEazCAAAAICMZhEAAAAAGc0iAAAAADKaRQAAAABkNIsAAAAAyBTku4CarqZNf1eR6vK5A5B/VT0VcG1gau+6pzJyUhueK64fsHZqw3WA0hlZBAAAAEBGswgAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMgU5LuAqmSKTKA0dfkaYfpToLRroGsEQN1TG679dfn9/doysggAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMhoFgEAAACQKch3ARWtMqbGM2VgxR6zNjye1FxVPX1mac/3yshQeY9pymwAaiLTYgPV6TpQm943G1kEAAAAQEazCAAAAICMZhEAAAAAGc0iAAAAADKaRQAAAABkNIsAAAAAyBTku4CaoDpNxQcsVxumpayMcyjtmOW9lpW2X234PcDKasNz2vsWKpvnGNQNdTnrteH9wNoysggAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMhoFgEAAACQKch3AdRcphOEmqW0zNblqVGpubwOwerV5Wt/ea8Rtf1xAZbzPqJ0RhYBAAAAkNEsAgAAACCjWQQAAABARrMIAAAAgIxmEQAAAAAZzSIAAAAAMgX5LqCi1ZTpQWvKVJ6mEwSgrKr6Nbi8x/TaBstVp/ejtSGXteEcqJ0q47lZnf62Lo1clp+RRQAAAABkNIsAAAAAyGgWAQAAAJDRLAIAAAAgo1kEAAAAQEazCAAAAIBMQb4LqEqmzSuZxwUojWsEtU1VT/dbG6YsLu3+XCPqntrwO68p035DdVXe60BlZK82XJOqIyOLAAAAAMhoFgEAAACQ0SwCAAAAIKNZBAAAAEBGswgAAACAjGYRAAAAAJmCfBdAcabDBSqDaYIhP2QPgLqkMl73/F1a9YwsAgAAACCjWQQAAABARrMIAAAAgIxmEQAAAAAZzSIAAAAAMppFAAAAAGQK8l0AVaO0qQZLm9qwvNMemtoQ8sMU3VRX5X1d8JyuHryuA7Cyynh99lpTvRhZBAAAAEBGswgAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMgU5LuAuqqqpxo0tSGsndIyVNVZKG+eZZaaqLzP28p43QMAqCuMLAIAAAAgo1kEAAAAQEazCAAAAICMZhEAAAAAGc0iAAAAADKaRQAAAABkCvJdABXHdNqwdkrLUFXnRJ5h7VRGFsqby5rC9YPapjIyKyfUJTJUtxlZBAAAAEBGswgAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMgU5LuA2qw6TbFrikJYrrRcljcnVZ11eYb8kD0AoK4wsggAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMhoFgEAAACQKch3AbVZaVPsVsZU26b0hbVTGbksL3kGgNXznhqqHxmqHYwsAgAAACCjWQQAAABARrMIAAAAgIxmEQAAAAAZzSIAAAAAMppFAAAAAGQK8l1AXWU6Qag95BkAgJoopZTvEqimjCwCAAAAIKNZBAAAAEBGswgAAACAjGYRAAAAABnNIgAAAAAymkUAAAAAZAryXQBAVTLNPQDg/QBA6YwsAgAAACCjWQQAAABARrMIAAAAgIxmEQAAAAAZzSIAAAAAMppFAAAAAGQK8l0AAAAAUPVyuVy+S6CaMrIIAAAAgIxmEQAAAAAZzSIAAAAAMppFAAAAAGQ0iwAAAADIaBYBAAAAkCnIdwEAAADlYdpvgMphZBEAAAAAGc0iAAAAADKaRQAAAABkNIsAAAAAyGgWAQAAAJDRLAIAAAAgk0sppXwXAQAAAED1YGQRAAAAABnNIgAAAAAymkUAAAAAZDSLAAAAAMhoFgEAAACQ0SwCAAAAIKNZBAAAAEBGswgAAACAjGYRAAAAAJn/D/7HiKV6qPJyAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель"
      ],
      "metadata": {
        "id": "IvsYC-qEkrfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Реализуйте VAE архитектуру"
      ],
      "metadata": {
        "id": "LOE45TA1MHl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ODO: РеализуTйте VAE (безусловный)\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=1, latent_dim=32, hidden_dim=128):\n",
        "        super(VAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Encoder: преобразует изображение в mu и logvar\n",
        "        # Decoder: преобразует z обратно в изображение\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_dim, 32, 4, 2, 1),  # уменьшаем размерность до 14x14\n",
        "            nn.ReLU(),  # нелинейная активация\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),  # уменьшаем размерность до 7x7\n",
        "            nn.ReLU(),  # нелинейная активация\n",
        "            nn.Flatten(),  # преобразуем в одномерный вектор\n",
        "            nn.Linear(3136, hidden_dim),  # переходим к вектору размерности hidden_dim\n",
        "            nn.ReLU(),  # нелинейная активация\n",
        "            nn.Linear(hidden_dim, 2 * latent_dim)  # получаем параметры распределения\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),  # расширяем latent вектор\n",
        "            nn.ReLU(),  # нелинейная активация\n",
        "            nn.Linear(hidden_dim, 3136),  # подготавливаем к преобразованию в изображение\n",
        "            nn.ReLU(),  # нелинейная активация\n",
        "            nn.Unflatten(1, (64, 7, 7)),  # восстанавливаем тензорную структуру\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1),  # увеличиваем размерность до 14x14\n",
        "            nn.ReLU(),  # нелинейная активация\n",
        "            nn.ConvTranspose2d(32, input_dim, 4, 2, 1),  # увеличиваем размерность до 28x28\n",
        "            nn.Sigmoid()  # активация для пикселей в диапазоне [0, 1]\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        # Получаем скрытое представление\n",
        "        h = self.encoder(x)\n",
        "        # Разделяем на mu и logvar\n",
        "        mu, logvar = h.chunk(2, dim=-1)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        # Вычисляем стандартное отклонение\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        # Генерируем случайный шум\n",
        "        eps = torch.randn_like(std)\n",
        "        # Применяем reparameterization trick\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        # Восстанавливаем изображение из latent пространства\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Кодируем входные данные\n",
        "        mu, logvar = self.encode(x)\n",
        "        # Генерируем latent переменную\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        # Декодируем latent переменную\n",
        "        p_recon = self.decode(z)\n",
        "\n",
        "        return p_recon, mu, logvar, z"
      ],
      "metadata": {
        "id": "UOTAmalSGlHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss"
      ],
      "metadata": {
        "id": "0P4f4GzioPUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Напишите VAE Loss"
      ],
      "metadata": {
        "id": "fC5Fg_VXFKa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Реализуйте функцию потерь VAE\n",
        "def vae_loss(p_recon, x, mu, logvar):\n",
        "    # Reconstruction loss: BCE (since output is sigmoid)\n",
        "    recon_loss = F.binary_cross_entropy(p_recon, x, reduction='sum')\n",
        "    # KL divergence: D_KL(q(z|x) || p(z))\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kl_loss, recon_loss, kl_loss"
      ],
      "metadata": {
        "id": "HP82mY2Pp7iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тренировка"
      ],
      "metadata": {
        "id": "euSht88Hkt4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Обучите модель на датасете MNIST."
      ],
      "metadata": {
        "id": "JWA7MSUoo4Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 32 # MNIST VAEs often use 20–64\n",
        "hidden_dim = 128\n",
        "epochs = 25\n",
        "lr = 1e-3\n",
        "img_size = 28\n",
        "channels = 1\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "zaw-ZH4qo5x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_vae(model, train_loader, epochs=1000):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  train_losses = []\n",
        "  recon_losses = []\n",
        "  kl_losses = []\n",
        "  best_loss = 1e38\n",
        "  best_model_state = None\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "      total_loss = 0\n",
        "      total_recon = 0\n",
        "      total_kl = 0\n",
        "      num_batches = 0\n",
        "\n",
        "      for i, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')):\n",
        "          x = batch[0].to(device)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          p_recon, mu, logvar, z = model(x)\n",
        "          loss, recon_loss, kl_loss = vae_loss(p_recon, x, mu, logvar)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          total_loss += loss.item()\n",
        "          total_recon += recon_loss.item()\n",
        "          total_kl += kl_loss.item()\n",
        "          num_batches += 1\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader.dataset)\n",
        "      avg_recon = total_recon / len(train_loader.dataset)\n",
        "      avg_kl = total_kl / len(train_loader.dataset)\n",
        "\n",
        "      train_losses.append(avg_loss)\n",
        "      recon_losses.append(avg_recon)\n",
        "      kl_losses.append(avg_kl)\n",
        "\n",
        "      print(f'На эпохе {epoch+1} Loss : {round(avg_loss, 4)}, Recon : {round(avg_recon, 4)}, KL : {round(avg_kl, 4)}')\n",
        "\n",
        "      if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model_state = model.state_dict().copy()\n",
        "\n",
        "  print(f'\\nЛучший Loss: {round(best_loss, 4)}')\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  return train_losses, recon_losses, kl_losses"
      ],
      "metadata": {
        "id": "lDJp84sMp_fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vae_model = VAE(input_dim=channels, latent_dim=latent_dim, hidden_dim=hidden_dim).to(device)\n",
        "vae_train_losses, vae_recon_losses, vae_kl_losses = train_vae(vae_model, train_loader, epochs=epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQvOqPIkHRYw",
        "outputId": "e63bd5b6-920f-4141-aa25-2342162b247d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/25: 100%|██████████| 118/118 [00:10<00:00, 10.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 1 Loss : 251.3649, Recon : 251.1629, KL : 0.202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/25: 100%|██████████| 118/118 [00:09<00:00, 12.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 2 Loss : 199.2837, Recon : 197.2493, KL : 2.0345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/25: 100%|██████████| 118/118 [00:08<00:00, 13.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 3 Loss : 184.2517, Recon : 178.9626, KL : 5.2892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/25: 100%|██████████| 118/118 [00:09<00:00, 12.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 4 Loss : 165.553, Recon : 157.0956, KL : 8.4574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/25: 100%|██████████| 118/118 [00:09<00:00, 12.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 5 Loss : 142.2155, Recon : 129.81, KL : 12.4055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/25: 100%|██████████| 118/118 [00:09<00:00, 12.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 6 Loss : 130.5663, Recon : 117.1074, KL : 13.4589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/25: 100%|██████████| 118/118 [00:09<00:00, 12.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 7 Loss : 125.3031, Recon : 111.944, KL : 13.3592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/25: 100%|██████████| 118/118 [00:09<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 8 Loss : 122.1181, Recon : 108.7366, KL : 13.3815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/25: 100%|██████████| 118/118 [00:09<00:00, 12.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 9 Loss : 119.2937, Recon : 105.8688, KL : 13.4249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/25: 100%|██████████| 118/118 [00:09<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 10 Loss : 116.9334, Recon : 103.5689, KL : 13.3645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/25: 100%|██████████| 118/118 [00:09<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 11 Loss : 115.0684, Recon : 101.7013, KL : 13.3671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/25: 100%|██████████| 118/118 [00:08<00:00, 13.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 12 Loss : 113.6741, Recon : 100.2058, KL : 13.4683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/25: 100%|██████████| 118/118 [00:09<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 13 Loss : 112.6719, Recon : 99.1596, KL : 13.5123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/25: 100%|██████████| 118/118 [00:09<00:00, 12.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 14 Loss : 111.7191, Recon : 98.1161, KL : 13.603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/25: 100%|██████████| 118/118 [00:09<00:00, 12.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 15 Loss : 111.0301, Recon : 97.335, KL : 13.6951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/25: 100%|██████████| 118/118 [00:08<00:00, 13.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 16 Loss : 110.319, Recon : 96.5349, KL : 13.7841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/25: 100%|██████████| 118/118 [00:09<00:00, 12.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 17 Loss : 109.735, Recon : 95.9074, KL : 13.8276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/25: 100%|██████████| 118/118 [00:09<00:00, 12.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 18 Loss : 109.3682, Recon : 95.4922, KL : 13.8759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/25: 100%|██████████| 118/118 [00:09<00:00, 12.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 19 Loss : 108.9168, Recon : 94.9632, KL : 13.9536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/25: 100%|██████████| 118/118 [00:09<00:00, 13.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 20 Loss : 108.4909, Recon : 94.4728, KL : 14.0181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/25: 100%|██████████| 118/118 [00:09<00:00, 12.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 21 Loss : 108.1161, Recon : 94.0421, KL : 14.074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/25: 100%|██████████| 118/118 [00:09<00:00, 12.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 22 Loss : 107.8064, Recon : 93.7057, KL : 14.1008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/25: 100%|██████████| 118/118 [00:09<00:00, 12.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 23 Loss : 107.6154, Recon : 93.4534, KL : 14.162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/25: 100%|██████████| 118/118 [00:08<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 24 Loss : 107.2863, Recon : 93.0968, KL : 14.1895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/25: 100%|██████████| 118/118 [00:09<00:00, 13.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На эпохе 25 Loss : 107.1978, Recon : 92.9678, KL : 14.23\n",
            "\n",
            "Лучший Loss: 107.1978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метрика"
      ],
      "metadata": {
        "id": "OqKZRnxnk2ON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом разделе вам необходимо посчитать метрику FID."
      ],
      "metadata": {
        "id": "Jm1SCUUjk42O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Что такое FID?**\n",
        "\n",
        "**FID (Fréchet Inception Distance)** — это метрика качества генеративных моделей для изображений, которая измеряет **расстояние между распределениями признаков реальных и сгенерированных изображений** в пространстве предобученной нейросети (обычно Inception-v3).\n",
        "\n",
        "Чем **ниже FID**, тем **ближе** сгенерированные изображения к реальным — как по **качеству**, так и по **разнообразию**.\n",
        "\n",
        "Формула FID основана на предположении, что признаки в этом пространстве приблизительно распределены как **многомерное нормальное распределение**:\n",
        "\n",
        "$$\n",
        "\\text{FID} = \\|\\mu_r - \\mu_g\\|^2 + \\mathrm{Tr}\\left( \\Sigma_r + \\Sigma_g - 2\\sqrt{\\Sigma_r \\Sigma_g} \\right)\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $(\\mu_r, \\Sigma_r)$ — среднее и ковариационная матрица признаков **реальных** изображений,\n",
        "- $(\\mu_g, \\Sigma_g)$ — то же для **сгенерированных** изображений,\n",
        "- $\\mathrm{Tr}(\\cdot)$ — след матрицы.\n",
        "\n",
        "> 🔹 FID = 0 означает полное совпадение распределений.  \n",
        "> 🔹 Чем выше FID ↑ , тем качество или разнообразие генерации ниже ↓."
      ],
      "metadata": {
        "id": "Weiu7gOmk_TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Как считать FID на MNIST?**\n",
        "\n",
        "Вычислите FID с помощью библиотеки [`pytorch-fid`](https://github.com/mseitzer/pytorch-fid):\n",
        "\n",
        "```bash\n",
        "python -m pytorch_fid real_mnist/ fake_mnist/ --device cuda\n",
        "```\n",
        "\n",
        "> **Важно**: несмотря на то, что признаки Inception-v3 не оптимальны для рукописных цифр, FID остаётся полезной **относительной метрикой** — она позволяет сравнивать разные модели между собой при одинаковых условиях предобработки.\n"
      ],
      "metadata": {
        "id": "TKKlXLdNlCGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание:** Сгенерируйте и сохраните 10 тыс. изображений, выберите 10 тыс. реальных изображений из MNIST тестовой выборки и посчитайте FID между реальными и сгенерированными изображениями."
      ],
      "metadata": {
        "id": "qI93gAkQEg7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Сгенерируйте и сохраните 10 тыс. изображений для FID в папке mnist_vae_fake\n",
        "vae_samples = 10000\n",
        "os.makedirs('mnist_vae_fake', exist_ok=True)  # Создаем директорию для сохранения\n",
        "\n",
        "# Отключаем вычисление градиентов для генерации\n",
        "with torch.no_grad():\n",
        "    # Генерируем случайные точки в латентном пространстве\n",
        "    z = torch.randn(vae_samples, vae_model.latent_dim).to(device)\n",
        "\n",
        "    # Декодируем точки в изображения\n",
        "    vae_fake_images = vae_model.decode(z)\n",
        "\n",
        "    # Бинаризуем изображения (пиксели > 0.5 становятся 1.0)\n",
        "    vae_fake_binary = (vae_fake_images > 0.5).float()\n",
        "\n",
        "    # Сохраняем каждое изображение отдельно\n",
        "    for i in range(vae_samples):\n",
        "        save_image(vae_fake_binary[i], f'mnist_vae_fake/mnist_vae_fake_{i:05d}.png')\n",
        "\n",
        "    print('Генерация завершена')"
      ],
      "metadata": {
        "id": "mqM9FD1rqEEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a457a40-28c9-476e-b61f-ec1b8c208ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генерация завершена\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтобы вычислить FID, запустите в терминале:\n",
        "!pip install pytorch-fid\n",
        "!python -m pytorch_fid mnist_vae_real mnist_vae_fake --device cuda"
      ],
      "metadata": {
        "id": "UzL3USg_riUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc5d0dd-7f85-4530-e949-e000c82e4e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.12/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n",
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:01<00:00, 64.3MB/s]\n",
            "100% 200/200 [00:37<00:00,  5.33it/s]\n",
            "100% 200/200 [00:37<00:00,  5.29it/s]\n",
            "FID:  6.59114043909841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **II Часть. Conditional VAE (6 баллов)**\n"
      ],
      "metadata": {
        "id": "rw-YrISFHgnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы уже научились обучать обычный VAE на датасете картинок и получать новые картинки. Давайте теперь научимся обучать модель, которая сможет генерировать не просто рандомную картинку, которая похожа на картинки из датасета, а картинку из конкретного класса. Например, в MNIST датасете 10 классов (от 1 до 10) и мы хотим говорить модели \"Сгенерируй мне только конкретно картинку с числом 3.\" и она должна теперь уже сгенерировать только картинку с числом 3. Как раз Conditional VAE это должен уметь делать и генерировать картинку, обуславливаясь на конкретный класс.\n",
        "\n",
        "\n",
        "**Задание**. В этой части домашнего задания вам предстоит обучить Conditional VAE на MNIST. Это значит, что модель на вход должна принимать картинку и класс картинки.\n",
        "\n",
        "**Метрика**. Вам нужно сгенерировать 1000 сэмплов на каждый класс и посчитать FID для каждого класса."
      ],
      "metadata": {
        "id": "OVMf6pBnHd8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# TODO: Реализуйте Conditional VAE — добавьте one-hot класс как вход в encoder и decoder\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, input_dim=1, latent_dim=32, hidden_dim=128, num_classes=10):\n",
        "        super(CVAE, self).__init__()\n",
        "        # TODO\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        # Архитектура как в VAE\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_dim + num_classes, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 2 * latent_dim)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim + num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 3136),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (64, 7, 7)),\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, input_dim, 4, 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x, c):\n",
        "        # TODO: конкатенируйте x и c по каналам\n",
        "        c = c.view(c.size(0), c.size(1), 1, 1).expand(-1, -1, x.size(2), x.size(3))\n",
        "        x = torch.cat([x, c], dim=1)\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h.chunk(2, dim=-1)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, c):\n",
        "        # TODO: конкатенируйте z и c\n",
        "        z = torch.cat([z, c], dim=1)\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        # TODO\n",
        "        mu, logvar = self.encode(x, c)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        p_recon = self.decode(z, c)\n",
        "        return p_recon, mu, logvar, z"
      ],
      "metadata": {
        "id": "YWFKXSxOJtwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Обучите CVAE\n",
        "def train_cvae(model, train_loader, epochs=1000):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "    recon_losses = []\n",
        "    kl_losses = []\n",
        "\n",
        "    best_loss = 1e38\n",
        "    best_model_state = None\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Цикл по эпохам обучения\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        total_recon = 0.0\n",
        "        total_kl = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        # Проходим по всем батчам в загрузчике данных\n",
        "        for idx, batch in enumerate(tqdm(train_loader, desc=f'Эпоха {epoch+1}/{epochs}')):\n",
        "            # Получаем данные и метки из батча\n",
        "            data = batch[0].to(device)\n",
        "            labels = batch[1]\n",
        "\n",
        "            # Подготавливаем one-hot представление меток\n",
        "            one_hot_labels = F.one_hot(labels, model.num_classes).float().to(device)\n",
        "\n",
        "            # Обнуляем градиенты перед каждым шагом\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Прямой проход через модель с учетом меток (CVAE)\n",
        "            p_recon, mu, logvar, z = model(data, one_hot_labels)\n",
        "\n",
        "            # Вычисляем компоненты функции потерь VAE\n",
        "            loss, recon_loss, kl_loss = vae_loss(p_recon, data, mu, logvar)\n",
        "\n",
        "            # Обратное распространение ошибки\n",
        "            loss.backward()\n",
        "\n",
        "            # Обновление весов модели\n",
        "            optimizer.step()\n",
        "\n",
        "            # Суммируем потери для статистики\n",
        "            total_loss += loss.item()\n",
        "            total_recon += recon_loss.item()\n",
        "            total_kl += kl_loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        # Вычисляем средние потери на эпохе\n",
        "        avg_loss = total_loss / len(train_loader.dataset)\n",
        "        avg_recon = total_recon / len(train_loader.dataset)\n",
        "        avg_kl = total_kl / len(train_loader.dataset)\n",
        "\n",
        "        # Сохраняем значения потерь\n",
        "        train_losses.append(avg_loss)\n",
        "        recon_losses.append(avg_recon)\n",
        "        kl_losses.append(avg_kl)\n",
        "\n",
        "\n",
        "        print(f'Эпоха {epoch+1}: Loss={avg_loss:.4f}, Recon={avg_recon:.4f}, KL={avg_kl:.4f}')\n",
        "\n",
        "        # Сохраняем лучшую модель\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model_state = model.state_dict().copy()\n",
        "\n",
        "    # Загружаем веса лучшей модели\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    # Выводим информацию о лучшей модели\n",
        "    print(f'\\nЛучший Loss: {best_loss:.4f}')\n",
        "\n",
        "    # Возвращаем историю потерь\n",
        "    return train_losses, recon_losses, kl_losses"
      ],
      "metadata": {
        "id": "x5KuxfgDtPCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "cvae_model = CVAE(input_dim=channels, latent_dim=latent_dim, hidden_dim=hidden_dim, num_classes=num_classes).to(device)\n",
        "cvae_train_losses, cvae_recon_losses, cvae_kl_losses = train_cvae(cvae_model, train_loader, epochs=epochs)"
      ],
      "metadata": {
        "id": "XMqbNINaSUpo",
        "outputId": "258eecdd-968c-4f9e-e5b3-e0844967dc9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 1/25: 100%|██████████| 118/118 [00:09<00:00, 12.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 1: Loss=237.3063, Recon=234.5574, KL=2.7488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 2/25: 100%|██████████| 118/118 [00:15<00:00,  7.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 2: Loss=182.0058, Recon=178.5967, KL=3.4090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 3/25: 100%|██████████| 118/118 [00:09<00:00, 12.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 3: Loss=143.6908, Recon=134.1121, KL=9.5787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 4/25: 100%|██████████| 118/118 [00:09<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 4: Loss=119.8218, Recon=105.4909, KL=14.3309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 5/25: 100%|██████████| 118/118 [00:08<00:00, 13.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 5: Loss=105.5122, Recon=88.4251, KL=17.0871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 6/25: 100%|██████████| 118/118 [00:09<00:00, 12.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 6: Loss=97.3626, Recon=78.9469, KL=18.4157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 7/25: 100%|██████████| 118/118 [00:12<00:00,  9.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 7: Loss=92.1834, Recon=72.9589, KL=19.2245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 8/25: 100%|██████████| 118/118 [00:09<00:00, 12.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 8: Loss=88.6052, Recon=68.7399, KL=19.8653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 9/25: 100%|██████████| 118/118 [00:09<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 9: Loss=85.8455, Recon=65.4875, KL=20.3580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 10/25: 100%|██████████| 118/118 [00:08<00:00, 13.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 10: Loss=83.8623, Recon=63.1357, KL=20.7266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 11/25: 100%|██████████| 118/118 [00:09<00:00, 12.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 11: Loss=82.0815, Recon=61.0438, KL=21.0377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 12/25: 100%|██████████| 118/118 [00:09<00:00, 11.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 12: Loss=81.0208, Recon=59.7795, KL=21.2413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 13/25: 100%|██████████| 118/118 [00:10<00:00, 10.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 13: Loss=79.9015, Recon=58.4787, KL=21.4228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 14/25: 100%|██████████| 118/118 [00:09<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 14: Loss=79.0812, Recon=57.4518, KL=21.6294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 15/25: 100%|██████████| 118/118 [00:08<00:00, 13.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 15: Loss=78.3227, Recon=56.5855, KL=21.7372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 16/25: 100%|██████████| 118/118 [00:09<00:00, 12.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 16: Loss=77.5883, Recon=55.7589, KL=21.8294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 17/25: 100%|██████████| 118/118 [00:09<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 17: Loss=76.9385, Recon=54.9950, KL=21.9435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 18/25: 100%|██████████| 118/118 [00:09<00:00, 12.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 18: Loss=76.4467, Recon=54.3973, KL=22.0494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 19/25: 100%|██████████| 118/118 [00:08<00:00, 13.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 19: Loss=76.0116, Recon=53.8925, KL=22.1190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 20/25: 100%|██████████| 118/118 [00:09<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 20: Loss=75.6626, Recon=53.5077, KL=22.1549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 21/25: 100%|██████████| 118/118 [00:09<00:00, 12.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 21: Loss=75.1710, Recon=52.9004, KL=22.2706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 22/25: 100%|██████████| 118/118 [00:09<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 22: Loss=74.9064, Recon=52.6054, KL=22.3010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 23/25: 100%|██████████| 118/118 [00:08<00:00, 13.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 23: Loss=74.4990, Recon=52.1250, KL=22.3741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 24/25: 100%|██████████| 118/118 [00:09<00:00, 12.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 24: Loss=74.2069, Recon=51.7900, KL=22.4170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Эпоха 25/25: 100%|██████████| 118/118 [00:09<00:00, 12.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 25: Loss=74.0752, Recon=51.6160, KL=22.4592\n",
            "\n",
            "Лучший Loss: 74.0752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Сгенерируйте 1000 сэмплов для каждого класса при помощи CVAE модели\n",
        "cvae_samples = 1000\n",
        "cvae_model.eval()\n",
        "\n",
        "# Создаем основную директорию для сохранения изображений\n",
        "os.makedirs('fake_per_class', exist_ok=True)\n",
        "\n",
        "# Отключаем вычисление градиентов для генерации\n",
        "with torch.no_grad():\n",
        "    # Проходим по всем классам (от 0 до num_classes-1)\n",
        "    for class_idx in range(num_classes):\n",
        "        # Создаем директорию для текущего класса\n",
        "        class_dir = f'fake_per_class/class_{class_idx}'\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        # Создаем условия для генерации: one-hot векторы для текущего класса\n",
        "        # Повторяем вектор текущего класса cvae_samples раз\n",
        "        conditions = torch.eye(num_classes).to(device)[[class_idx] * cvae_samples]\n",
        "\n",
        "        # Генерируем случайные точки в латентном пространстве\n",
        "        latent_vectors = torch.randn(cvae_samples, cvae_model.latent_dim).to(device)\n",
        "\n",
        "        # Декодируем латентные векторы с учетом условий (меток класса)\n",
        "        cvae_fake_images = cvae_model.decode(latent_vectors, conditions)\n",
        "\n",
        "        # Бинаризуем изображения (пиксели > 0.5 становятся 1.0)\n",
        "        cvae_fake_binary = (cvae_fake_images > 0.5).float()\n",
        "\n",
        "        # Сохраняем все сгенерированные изображения для текущего класса\n",
        "        for img_idx in range(cvae_fake_binary.shape[0]):\n",
        "            save_image(cvae_fake_binary[img_idx], f'{class_dir}/fake_{img_idx:05d}.png')\n",
        "\n",
        "    print('Генерация изображений для всех классов завершена')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gqp8lv75uuL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffa0fa5-1d5f-48d0-9289-ce42e360d656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генерация изображений для всех классов завершена\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Сохраните 1000 сэмплов для каждого класса из реального датасета MNIST тестовой части\n",
        "\n",
        "real_mnist_samples = 1000\n",
        "os.makedirs('real_class', exist_ok=True)\n",
        "\n",
        "# Создаем словарь для хранения индексов изображений по классам\n",
        "class_dict = {class_label: [] for class_label in range(10)}\n",
        "\n",
        "# Собираем индексы изображений для каждого класса (до 1000 на класс)\n",
        "for idx, (_, label) in enumerate(test_dataset):\n",
        "    if len(class_dict[label]) < real_mnist_samples:\n",
        "        class_dict[label].append(idx)\n",
        "\n",
        "# Сохраняем изображения для каждого класса\n",
        "for class_label, indices in class_dict.items():\n",
        "    class_dir = f'real_class/class_{class_label}'\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    for position, dataset_idx in enumerate(indices):\n",
        "        img, _ = test_dataset[dataset_idx]\n",
        "        save_image(img, f'{class_dir}/real_{position:05d}.png')\n",
        "\n",
        "print('Сохранение реальных изображений MNIST завершено')"
      ],
      "metadata": {
        "id": "bOL3a8bRffOD",
        "outputId": "c367934c-80c0-4ad9-b3fb-ab18760efc6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сохранение реальных изображений MNIST завершено\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Посчитайте FID для каждого класса между сгенерированными и реальными изображениями\n",
        "for i in range(num_classes):\n",
        "    print(f\"\\nClass {i}\")\n",
        "    real_dir = f'real_class/class_{i}'\n",
        "    fake_dir = f'fake_per_class/class_{i}'\n",
        "    !python -m pytorch_fid {real_dir} {fake_dir} --device cuda"
      ],
      "metadata": {
        "id": "PJSeXhiVxz_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93afb65c-a328-4862-d0a7-267f46e6a471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class 0\n",
            "100% 20/20 [00:04<00:00,  4.98it/s]\n",
            "100% 20/20 [00:03<00:00,  5.23it/s]\n",
            "FID:  7.614651411875585\n",
            "\n",
            "Class 1\n",
            "100% 20/20 [00:04<00:00,  4.91it/s]\n",
            "100% 20/20 [00:03<00:00,  5.21it/s]\n",
            "FID:  10.700727848149711\n",
            "\n",
            "Class 2\n",
            "100% 20/20 [00:04<00:00,  4.81it/s]\n",
            "100% 20/20 [00:03<00:00,  5.21it/s]\n",
            "FID:  13.212338933176369\n",
            "\n",
            "Class 3\n",
            "100% 20/20 [00:04<00:00,  4.89it/s]\n",
            "100% 20/20 [00:03<00:00,  5.21it/s]\n",
            "FID:  6.65112396623303\n",
            "\n",
            "Class 4\n",
            "100% 20/20 [00:04<00:00,  4.96it/s]\n",
            "100% 20/20 [00:03<00:00,  5.18it/s]\n",
            "FID:  9.16257895681926\n",
            "\n",
            "Class 5\n",
            "100% 18/18 [00:03<00:00,  4.83it/s]\n",
            "100% 20/20 [00:03<00:00,  5.16it/s]\n",
            "FID:  9.326540042560609\n",
            "\n",
            "Class 6\n",
            "100% 20/20 [00:04<00:00,  4.95it/s]\n",
            "100% 20/20 [00:03<00:00,  5.18it/s]\n",
            "FID:  8.64736772306668\n",
            "\n",
            "Class 7\n",
            "100% 20/20 [00:04<00:00,  4.87it/s]\n",
            "100% 20/20 [00:03<00:00,  5.16it/s]\n",
            "FID:  12.246075037898663\n",
            "\n",
            "Class 8\n",
            "100% 20/20 [00:04<00:00,  4.95it/s]\n",
            "100% 20/20 [00:03<00:00,  5.16it/s]\n",
            "FID:  10.278216949373842\n",
            "\n",
            "Class 9\n",
            "100% 20/20 [00:04<00:00,  4.86it/s]\n",
            "100% 20/20 [00:03<00:00,  5.12it/s]\n",
            "FID:  8.072185290994355\n"
          ]
        }
      ]
    }
  ]
}