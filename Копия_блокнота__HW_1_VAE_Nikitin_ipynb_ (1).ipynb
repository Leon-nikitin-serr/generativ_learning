{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Автор**: Ермекова Асель\n",
        "\n",
        "В этом домашнем задании вам предстоит реализовать VAE для датасета картинок MNIST.\n",
        "\n",
        "Вы научитесь обучать вариационный автоэнкодер (VAE) генерировать новые изображения с нуля. А также сможете управлять генерацией, указывая желаемый класс объекта, и оценивать качество результата с помощью метрики FID.\n",
        "\n",
        "Это домашнее задание состоит из двух частей:\n",
        "\n",
        "* **I часть.** Реализовать безусловную генерацию картинок при помощи VAE тренированную на датасете MNIST и оценить качество по метрике FID.\n",
        "* **II часть.** Реализовать условную генерацию по классу и оценить качество по метрике FID.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "zPQ-a1t0gOO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установите библиотеку для подсчета FID:"
      ],
      "metadata": {
        "id": "L2D3ZgfKISwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-fid"
      ],
      "metadata": {
        "id": "IhYp4gS8ox32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f242f3-6be9-4e20-885b-f2cbf4c7193a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n",
            "Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **I часть. Unconditional VAE (6 баллов)**"
      ],
      "metadata": {
        "id": "gc-Nwikdf1EY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Библиотеки"
      ],
      "metadata": {
        "id": "yG1utf_ZoFXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# Импортните любые необходимые вам библиотеки\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import random"
      ],
      "metadata": {
        "id": "CCEPzS2qoHhG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Датасет."
      ],
      "metadata": {
        "id": "zFU4Gu4vkpf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Скачайте датасет MNIST и подготовьте train dataloader."
      ],
      "metadata": {
        "id": "V3JalSoZqutl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Подготовка данных ---\n",
        "batch_size = 128  # Размер батча\n",
        "\n",
        "# Визуально переформатированный пайплайн преобразований\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "# Загрузка датасета MNIST для обучения\n",
        "train_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# Создание загрузчика данных\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "XauYmn9KtMgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890e930f-7aa9-4930-ca25-9606e9f09e6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 128MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 34.9MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 63.8MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.00MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Для FID сохраните 10k реальных изображений из MNIST test части в папку"
      ],
      "metadata": {
        "id": "d3uNroE4L5Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Для FID сохраните 10k реальных изображений из MNIST test части в папку\n",
        "\n",
        "# Создаем целевую директорию для хранения реальных изображений\n",
        "\n",
        "# Папка для сохранения реальных изображений\n",
        "real_images_dir = 'mnist_vae_real'\n",
        "os.makedirs(real_images_dir, exist_ok=True)\n",
        "\n",
        "num_images_to_save = 10000\n",
        "saved_count = 0\n",
        "\n",
        "# Сохранение 10 000 реальных изображений\n",
        "for i, (img, label) in enumerate(test_dataset):\n",
        "    if saved_count >= num_images_to_save:\n",
        "        break\n",
        "\n",
        "    # Нормализация [0, 1] -> [0, 255] и конвертация в PIL Image\n",
        "    img = img * 0.5 + 0.5  # Денормализация из [-1, 1] -> [0, 1]\n",
        "    img = transforms.ToPILImage()(img)\n",
        "\n",
        "    img_path = os.path.join(real_images_dir, f'real_mnist_{i}.png')\n",
        "    img.save(img_path)\n",
        "    saved_count += 1\n",
        "\n",
        "print(f\"Сохранено {saved_count} реальных изображений MNIST в папку '{real_images_dir}'\")"
      ],
      "metadata": {
        "id": "urDPJe8DGqGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f59e2eb-fbd0-4c67-8b48-0dc9441c943b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сохранено 10000 реальных изображений MNIST в папку 'mnist_vae_real'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Визуализируйте 5 рандомных сэмплов из тренировочных данных и 5 сэмплов из тестовых данных"
      ],
      "metadata": {
        "id": "Z7HWBHlkq4Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "fig, axes = plt.subplots(2, 5, figsize = (12, 5))\n",
        "\n",
        "# Отображение примеров из обучающей выборки\n",
        "for idx in range(5):\n",
        "    sample_idx = random.randint(0, len(train_dataset)-1)\n",
        "    image, target = train_dataset[sample_idx]\n",
        "    axes[0, idx].imshow(image[0], cmap = 'gray')\n",
        "    axes[0, idx].set_title(f'Обучающий пример {idx+1}\\nМетка: {target}')\n",
        "    axes[0, idx].axis('off')\n",
        "\n",
        "# Отображение примеров из тестовой выборки\n",
        "for j in range(5):\n",
        "    sample_idx = random.randint(0, len(test_dataset) - 1)\n",
        "    image, target = test_dataset[sample_idx]\n",
        "    axes[1, j].imshow(image[0], cmap='gray')\n",
        "    axes[1, j].set_title(f'Тестовый пример {j+1}\\nМетка: {target}')\n",
        "    axes[1, j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V_ug8vGxCjET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "e41ddb3f-384c-410d-f3a5-efdab616703f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAHxCAYAAADtDjxuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZnVJREFUeJzt3X18j/X////Haxs7MSHn5+T8/GQiORtGznMyCgn5OIkS76IoZ29niZjkLNWEqYxMqQx9Z0Ii3nJexJyLiRnD2J6/P/x2ZLbn4eXYa3vttd2ul8sulzrux8nj2PbYa3s4tqdNKaUEAAAAAAAAEBE3ZxcAAAAAAACAzINhEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMDh1WHTz5k05c+aMXL161ZllALATPQu4FnoWcC30LOBa6FlkZRk+LAoNDZWWLVtK7ty5xdfXV0qVKiUffPBBRpfhstavXy/79u0z/j8sLEwOHTrkvIKQ5dGzaUPPIqPRs2lDzyKj0bNpQ88io9GzaUPPuo40DYsOHTokL730khQvXlw8PT2lWLFi0rt3b+0H+5133pEePXpI7ty5ZcmSJbJp0ybZvHmzDB06NC1lZCsHDhyQN954Q44dOyY7d+6UIUOGSGxsrLPLcnkLFy6U7t27S6lSpcRms0m/fv2cXVK6oGczHj3reGfOnJFJkyZJ/fr1JV++fFKgQAHx9/eXzZs3O7s0h6NnMx4963i3bt2SAQMGSPXq1SVPnjzi6+srtWrVkrlz58rdu3edXZ5D0bMZj55Nf9u2bRObzSY2m02io6OdXY5D0bMZj55NH0k9+vDb+++/b/2kyqI1a9aonDlzqiJFiqh3331Xffrpp+q9995TRYsWVTlz5lTffPNNsv23bNmiRERNnz7d6iWhlLp06ZIqX768EhElIqpr167OLilLKF26tHryySdVmzZtlIeHh+rbt6+zS3I4etY56FnHmzdvnvL29lY9e/ZUH3/8sQoKClJ169ZVIqI+//xzZ5fnMPSsc9CzjnflyhXVoEEDNWrUKDV//ny1cOFC1adPH2Wz2VTPnj2dXZ7D0LPOQc+mr4SEBFW7dm2VK1cuJSLq8uXLzi7JYehZ56Bn04eIqFatWqnly5cnezt48KD1c1o56Pjx48rHx0dVrlxZXbp0KVl2+fJlVblyZZUrVy71119/Gds7dOignn32WcuF4l+3b99Wv/32mzp8+LCzS8kyoqKiVGJiolJKqVy5cmW5YRE961z0rGMdPHgwxTert2/fVpUrV1YlSpRwUlWORc86Fz2bMV577TUlIurChQvOLiXN6FnnomfTz8KFC1X+/PnVG2+8kaWGRfSsc9GzjiciatiwYY49p5WDBg8erEREbd26NdU8MjJSiYgaPHiwsa1AgQJq0KBB6oUXXlD58uVTXl5eql69emrt2rXGPrGxscrHx0cNHz48xTnPnDmj3Nzc1LRp05RSSvXt21eVLl065Q2JqAkTJhj/HxUVpV599VVVsWJF5eXlpZ588kkVGBioTp48mey4iIgIJSIqIiLC2LZr1y4VEBCgfH19lY+Pj2rWrFmKew4ODlYionbv3m1su3z5coo6lFKqffv2KWpu1qyZatasWbJtu3btMiatZvemlFIffPCBEpEU50hN0jlTe3uwrpMnTyoRUTNnzlSzZ89WpUqVUl5eXqpp06bqwIEDyc6Z2sfh9OnTysvLS4lIsvdz6dKllYioN954I0VtrVu3ViKi2rdvn2z77du31fjx41W5cuVUzpw5VYkSJdSoUaPU7du3U9zbsGHD1IoVK1TFihWVp6enqlu3roqMjHzk++VhWXFYRM/+i57Nej2b5D//+Y8SEXX9+nXL58gs6Nl/0bNZt2dnzZqlREQdOXLE8jkyC3r2X/Rs1unZK1euqPz586v58+erCRMmZKlhET37L3o2a/Rs0vFxcXHq1q1bdh3zKB5iwXfffSdlypSRJk2apJo3bdpUypQpI99//72x7cqVK/LJJ5+Ir6+vDB8+XAoWLCgrVqyQrl27SkhIiPTs2VN8fX2lS5cu8vXXX8vs2bPF3d3dOP7LL78UpZT07t37sWrdvXu37NixQ1588UUpUaKEREVFycKFC8Xf318OHz4sPj4+qR53/Phx8ff3Fx8fHxk1apT4+PjIkiVLJCAgQDZt2iRNmzZ9rDoex9tvv23XfteuXZPp06c/1rlbtWolL7/8crJtH374Yap/wX/ZsmUSGxsrw4YNk9u3b8vcuXOlRYsWcuDAASlcuLD2GuPHj5fbt2+nmnl5eUlISIjMnDlTcuTIISIiZ8+elZ9++km8vLyS7ZuYmCidOnWSbdu2yaBBg6RKlSpy4MABmTNnjvz5558SFhaWbP/IyEj5+uuvZfjw4eLp6SkLFiyQNm3ayK5du6R69er2vHuyLHqWns0OPXvx4kXx8fHRfo64EnqWns2KPRsfHy/Xr1+XW7duyW+//SazZs2S0qVLS/ny5R95bGZHz9KzWbFnx40bJ0WKFJHBgwfL5MmTH7m/K6Fn6dms2LNLly6VBQsWiFJKqlSpIu+995706tXrkcdpPe506dq1a0pE1PPPP2+6X6dOnZL9C6/8/xO/LVu2GPvExcWpKlWqqCJFiqj4+HillFLh4eFKRNSPP/6Y7Hw1a9ZMNm3s37+/KlWqVIrrykPTyri4uBT7/PLLL0pE1LJly4xtD09iu3Xrptzd3ZP9jl90dLTKnz+/8vPzM7Y5ehL7ww8/KBFRbdq0eeQkdvTo0apQoULKz8/P7klsao+mPVxX0iTW29tbnT171tj+66+/KhFRI0eONLY9PIk9ePCgcnNzU23btk11EtuqVStVoEABtXr1amP75MmT1bPPPqtKly6dbBK7fPly5ebmpn7++edk9S5atEiJiNq+fXuyexMR9dtvvxnbTp06pby8vFSXLl0e+b55UFZ7soiepWezes8qpdSxY8eUl5eX6tOnz2Mfm9nQs/RsVu3ZL7/8Mtm/AterV0/t37/frmMzM3qWns2KPfv7778rd3d3FR4erpRSWerJInqWns2KPfvss8+qoKAgtW7dOrVw4UJVvXp1JSJqwYIFjzxW57FXQ0v6S+W5c+c23S8pv379urHt6aeflmbNmhn/7+3tLUOHDpWLFy/K3r17RUQkICBAihUrJiEhIcZ+Bw8elP3798tLL71kbCtUqJBcunRJ4uPjTevw9vY2/vvu3bty5coVKV++vOTNm9e45oNiYmLk0qVLsmnTJnnuueekWrVqRpY/f37p16+f7NmzR/7++2/T61qhlJIxY8ZIt27dpEGDBqb7njt3TubNmyfjxo0TX19fh9ciItK5c2cpXry48f/169eXBg0ayA8//KA9ZsyYMVK3bl3p3r17qnnOnDmld+/eEhwcbGxbunSp9O/fP8W+oaGhUqVKFalcubJER0cbby1atBARkYiIiGT7N2zYUPz8/Iz/L1WqlDz//PMSHh4uCQkJ9t10FkTP0rNZvWfj4uKke/fu4u3tnbYVHzIJepaezao927x5c9m0aZOEhobKkCFDJEeOHHLz5s1HHpfZ0bP0bFbs2eHDh0vbtm2ldevWpvu5InqWns2KPbt9+3Z54403pFOnTjJkyBDZs2ePVK9eXcaOHSu3bt0yPVbnsYdFSU3zqOXtUmvCypUrp9ivSpUqIiISFRV1vyA3N+ndu7eEhYVJXFyciIiEhISIl5dXsg/Ys88+K7dv35b33ntPzp49a7zjH3br1i0ZP368lCxZUjw9PaVAgQJSsGBBuXbtmsTExKTYv3PnzlK4cGG5fv26VKpU6ZH1OlJISIgcOnRIpk2b9sh9J0yYIMWKFZPBgwc7vI4kFSpUSLGtYsWK2nvftm2bfPfddzJjxgyx2Wza8/bv3182bNggFy5ckMjISLlw4YL06NEjxX7Hjh2TQ4cOScGCBZO9VaxYUURELl26ZFe9cXFxcvnyZbNbzdLoWXo2K/dsQkKCvPjii3L48GFZvXq1FCtWzK7jMjN6lp7Nqj1buHBhCQgIkMDAQFm4cKF06NBBWrVqJRcvXnzksZkZPUvPZrWe/frrr2XHjh3y4YcfavdxZfQsPZvVejY1OXPmlNdee02uXbsme/bseaxjkzz23yzKkyePFC1aVPbv32+63/79+6V48eLyxBNPiEjyieijvPzyyzJz5kwJCwuTnj17ysqVK6VDhw6SJ08eY59OnTrJK6+8IjNnzpSZM2dqz/X6669LcHCwjBgxQho2bCh58uQRm80mL774oiQmJqbYf9asWVKhQgV5/vnn7a7XEeLj42XcuHEyYMAA45NH58iRI7J06VJZsWKF8XuSmcHbb78tzz33nLRo0UKWLl2q3a9WrVpSq1YtWbZsmRw5ckS6detmfJ48KDExUWrUqCGzZ89O9TwlS5Z0VOlZGj2bPujZzNGzAwcOlPXr10tISIjxrzSujp5NH/Rs5ujZBwUGBsq7774r69atS9cfFtIbPZs+6Fnn9eyoUaOke/fukjNnTuOH6mvXromIyJkzZyQ+Pt6l/3GGnk0f9Gzme51NOv8///xj6XhLf+C6Q4cOsmTJEtm2bZs0btw4Rf7zzz9LVFRUshf+smXLyh9//JFi36NHj4qISJkyZYxt1atXlzp16khISIiUKFFCTp8+LfPmzUtx7GeffSbjx4+Xv/76y2iUVq1aJdtn9erV0rdv32ST8du3bxtf8B7m5+cnzZo1E19fX7vrdYQFCxbIpUuXZOLEiY/cd8yYMVK7dm154YUXHFrDw44dO5Zi259//pnqvYeFhckvv/yS6qOQqXnllVdkzpw5cvHiRfnuu+9S3adcuXLy+++/S8uWLU0nu4+q18fHRwoWLGhXXVkVPUvPPiwr9OyoUaMkODhYgoKCpGfPno++CRdCz9KzD8sKPfuwpMfiU/uXcVdDz9KzD3Plnj1z5oysXLlSVq5cmSKrW7eu1KpVS/bt2/fI62dm9Cw9+zBX7lmdEydOiIhY/ln4sX8NTeT+N+je3t4yePBguXLlSrLsn3/+kSFDhhh/dT1Ju3btZNeuXbJjxw5j2+3bt2XhwoVSpEiRZL+bJyLSp08f2bhxowQFBUn+/Pmlbdu2qdZSunRpadGihQQEBEhAQECK3N3dXe7/vah/zZs3z/R3/mw2m7Ru3VrCw8PlyJEjye7tiy++kHr16pn+9fTHFRsbK1OnTpWRI0dKkSJFTPf95ZdfZN26dfL+++/b9QmXFmFhYXLu3Dnj/3ft2iW//vprio9FQkKCjB07Vnr16iW1a9e269y9evWSc+fOSaFChcTf3z/VfXr06CHnzp2TJUuWpMhu3bqV4u8cPNzcZ86ckXXr1knr1q2TrUSQHdGz9OyDskLPzpw5U2bNmiVjx46VN954w657cCX0LD37IFfv2ejo6BSfIyIin376qYiI1KtXz55bytToWXr2Qa7es2vXrk3xlvRD/bJly2TOnDl23VNmRs/Ssw9y9Z5N7VfUYmNjJSgoSAoUKJDic9Nelp4sqlChgnzxxRfSu3dvqVGjhgwYMEDKli0rUVFR8tlnn0l0dLR8+eWXUq5cOeOY0aNHS0hIiLRt21aGDx8uBQoUkBUrVsjhw4clJCREPDySl9KrVy8ZPXq0rF27Vl599VXLj6d16NBBli9fLnny5JGqVavKL7/8Ips3b5b8+fObHjd58mQJDw+XZs2ayeuvv24sNXjt2jVZvXp1iv1/+eUX43dMk/4I2vHjx2XDhg3GPpcvX5Zbt27Jhg0bpE2bNsb2vXv3SoECBWT06NGPvJ+NGzdKq1atUv1C4mjly5eXxo0by6uvvip37twxvtA9XOfZs2clZ86cpn8o7GH58uWTCxcuiLu7u/aLRJ8+fWTVqlUyZMgQiYiIkEaNGklCQoIcPXpUVq1aJeHh4cm+waxevbo899xzyZYaFBGZNGnSI+v57rvv5PfffxeR+384bv/+/TJlyhQRuf+IaM2aNe2+t8yInqVnH+TqPbt27VoZPXq0VKhQQapUqSIrVqxIlrdq1cqh3wA5Az1Lzz7I1Xt2xYoVsmjRIuncubM89dRTEhsbK+Hh4bJp0ybp2LFjlvgVUnqWnn2Qq/ds586dU2xLepKobdu2UqBAAbvvK7OiZ+nZB7l6z86fP1/CwsKkY8eOUqpUKblw4YJ8/vnncvr0aVm+fLnkzJnT7vtKxvI6akqp/fv3q549e6qiRYuqHDlyqCJFiqiePXuqAwcOpLr/X3/9pQIDA1WePHmUl5eXevrpp1VYWJj2/O3atVMionbs2GF3TfLQcnxXr15V/fv3VwUKFFC+vr7queeeU0ePHlWlS5dOtjz6w0sNKqXUnj17VOvWrZWvr6/y8fFRTZs2VZGRkcmul7TU4OO+JWnWrJkSETVnzpxk501anvLhe7PZbGrPnj3Jtj+8XKHZ++ZxlhqcOXOm+vDDD1XJkiWVp6enatKkifr999+THdu3b18lIuqNN95I9f3y8FKDDy4l+LDU8vj4eDVjxgxVrVo15enpqfLly6f8/PzUpEmTVExMTIp7W7FihapQoYLy9PRUderUSfbxNJN0H6m9BQcH23UOV0DP0rNZoWeT3te6N3v73hXQs/RsVujZ3bt3q+7du6tSpUopT09PlStXLlW3bl01e/Zsdffu3Uce70roWXo2K/RsapLe/5cvX7Z0fGZFz9KzWaFnN27cqFq1aqWKFCmicuTIofLmzatat26tfvrpp0ceayZNw6L01rlzZ1WuXDlnl+FQSZ+4mdmDzeUqdF84kLHoWeegZ2EVPesc9Cysomedg56FVfSsc9CzjmHpbxZlhAsXLsj3338vffr0cXYpAOxAzwKuhZ4FXAs9C7gWehauztLfLEpPJ0+elO3bt8unn34qOXLkcOmlVFPj7e0tzz33nLPLAByGngVcCz0LuBZ6FnAt9Cyyikz3ZFFkZKT06dNHTp48KV988cUj/5q6qylcuHCyPxIGuDp6FnAt9CzgWuhZwLXQs8gqbEqlspYpAAAAAAAAsqVM92QRAAAAAAAAnIdhEQAAAAAAAAwMiwAAAAAAAGBgWGRi6dKlYrPZxGazybZt21LkSikpWbKk2Gw26dChgxMqzHjXrl2TQoUKic1mk9WrVzu7HCAZejYlehaZGT17X2JioixatEhq164tvr6+UrhwYWnbtq3s2LHD2aUBydCz923cuFEGDBgg1atXF3d3dylTpoyzSwJSRc/ex+usNQyL7ODl5SUrV65MsT0yMlLOnj0rnp6eTqjKOcaPHy9xcXHOLgMwRc/+i56FK8juPTtq1Ch59dVXpUaNGjJ79mx588035c8//5RmzZrJrl27nF0ekEJ279mVK1fKypUrJU+ePFKsWDFnlwM8UnbvWV5nrWFYZId27dpJaGio3Lt3L9n2lStXip+fX5ZbDlHn4MGDsnDhQnn77bedXQpgip69j56Fq8jOPXvv3j1ZuHChBAYGyvLly2XQoEEyevRo2bx5s9y7d09CQkKcXSKQQnbuWRGRadOmyfXr12X79u1Sq1YtZ5cDPFJ27lleZ61jWGSHnj17ypUrV2TTpk3Gtvj4eFm9erX06tUr1WMSExMlKChIqlWrJl5eXlK4cGEZPHiwXL161dinTJkyxmOBqb0lPdIaFRUlNptNli5dahwbGxsrfn5+UrZsWblw4YKxfdasWfLss89K/vz5xdvbW/z8/FL91ZPo6Gg5evToYz1x8MYbb0iXLl2kSZMmdh8DOAM9ex89C1eRnXv27t27cuvWLSlcuHCy7YUKFRI3Nzfx9vY2PR5whuzcsyIixYoVkxw5cjxyPyCzyM49y+usdR7OLsAVlClTRho2bChffvmltG3bVkREfvzxR4mJiZEXX3xRPvrooxTHDB48WJYuXSr9+/eX4cOHy8mTJ+Xjjz+W//3vf7J9+3bJkSOHBAUFyY0bN0RE5MiRIzJt2jQZO3asVKlSRUREfH19U63n7t270q1bNzl9+rRs375dihYtamRz586VTp06Se/evSU+Pl6++uor6d69u6xfv17at29v7Pfxxx/LpEmTJCIiQvz9/R/5PggNDZUdO3bIkSNHJCoqyt53HeAU9Cw9C9eSnXvW29tbGjRoIEuXLpWGDRtKkyZN5Nq1azJ58mTJly+fDBo06LHfn0B6y849C7ii7NyzvM6mgYJWcHCwEhG1e/du9fHHH6vcuXOruLg4pZRS3bt3V82bN1dKKVW6dGnVvn1747iff/5ZiYgKCQlJdr4NGzakul0ppSIiIpSIqIiIiBTZyZMnlYio4OBglZiYqHr37q18fHzUr7/+mmLfpPqSxMfHq+rVq6sWLVok2z5hwgTt9VI7Z6lSpdSYMWOS1RoaGvrIY4GMRM/+e056Fq6Anr3v2LFjqm7dukpEjLennnpKHT169JHHAhmJnk2pffv2qnTp0o91DJBR6Nn7eJ21hl9Ds1OPHj3k1q1bsn79eomNjZX169drH9kLDQ2VPHnySKtWrSQ6Otp48/PzE19fX4mIiLBcx6hRoyQkJERWrVol9evXT5E/+Bjd1atXJSYmRpo0aSJ79+5Ntt/EiRNFKWXXv5y8//77cvfuXRk7dqzluoGMRs/Ss3At2blnc+fOLdWqVZNhw4bJN998IwsWLJB79+5J586dJTo62vK9AOkpO/cs4Iqyc8/yOmsNv4Zmp4IFC0pAQICsXLlS4uLiJCEhQQIDA1Pd99ixYxITEyOFChVKNb906ZKlGhYvXiw7d+4UEUn2u6IPWr9+vUyZMkX27dsnd+7cMbbbbDZL14yKipKZM2fK/PnztY8RApkRPUvPwrVk1569d++eBAQEiL+/v8ybN8/YHhAQINWqVZOZM2fKjBkzLJ0bSE/ZtWcBV5Vde5bXWesYFj2GXr16ycCBA+XixYvStm1byZs3b6r7JSYmSqFChbR/Wb1gwYKWrr9z506ZOnWq7N69W0aOHClt2rSRAgUKGPnPP/8snTp1kqZNm8qCBQukaNGikiNHDgkODk51qUR7jB8/XooXLy7+/v7G3z25ePGiiIhcvnxZoqKipFSpUuLmxkNqyHzo2SgRoWfhOrJjz27dulUOHjwos2fPTra9QoUKUqVKFdm+fbul8wIZITv2LODKsmPP8jprHcOix9ClSxcZPHiw7Ny5U77++mvtfuXKlZPNmzdLo0aNHPrX1V955RUZO3asnD9/XqpWrSojR46U5cuXG/maNWvEy8tLwsPDxdPT09geHBxs+ZqnT5+W48ePy1NPPZUiGzp0qIjcnwrrvtAAzkTPJkfPIrPLjj37999/i4hIQkJCiuzu3bspljkGMpPs2LOAK8uOPcvrrHX80/Jj8PX1lYULF8rEiROlY8eO2v169OghCQkJMnny5BTZvXv35Nq1a5aun7T8dbFixWTGjBmyYsUK2bhxo5G7u7uLzWZL1ghRUVESFhaW4lz2LjU4ZcoUWbt2bbK3pPsaPXq0rF27VnLlymXpfoD0Rs/Ss3At2bFnK1asKCIiX331VbLte/fulT/++EPq1Klj6V6AjJAdexZwZdmxZ3mdtY4nix5T3759H7lPs2bNZPDgwTJ9+nTZt2+ftG7dWnLkyCHHjh2T0NBQmTt3rvb3Q+01aNAgWblypQwZMkQOHjwoPj4+0r59e5k9e7a0adNGevXqJZcuXZL58+dL+fLlZf/+/cmOt3epwcaNG6fYlvREwtNPPy2dO3dO030A6Y2epWfhWrJbz/r5+UmrVq3kiy++kOvXr0vr1q3lwoULMm/ePPH29pYRI0ak6T6A9JbdelZEZP/+/fLtt9+KiMjx48clJiZGpkyZIiIitWrVMv0hHHC27NazvM5ax7AonSxatEj8/Pxk8eLFMnbsWPHw8JAyZcrISy+9JI0aNUrz+W02myxZskRq1aol7733nsyePVtatGghn332mbz//vsyYsQIKVu2rMyYMUOioqJSNBeA5OhZwLVkpZ5dt26dzJo1S7766ivZsGGD5MyZU5o0aSKTJ0+WSpUqpflegMwgK/Xs3r17Zdy4ccm2Jf1/3759GRYhS8hKPcvrrDU2pZRydhEAAAAAAADIHPibRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwOBh7442my096wBcilLK2SU8Ej0L/IueBVwLPQu4FnoWcC329CxPFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAgWERAAAAAAAADAyLAAAAAAAAYGBYBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAgWERAAAAAAAADAyLAAAAAAAAYGBYBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAgWERAAAAAAAADAyLAAAAAAAAYGBYBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGD2cXAAAAAACZhb+/vzaLiIiwdE6bzWaxGgBwDp4sAgAAAAAAgIFhEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAYFNKKbt2ZLlHwGBn2zgVPQv8i57Nfvr166fN+vTpo81atGihzcw+j86cOaPNfvrpJ23Wtm1bbfbOO+9oM7Plu0+fPq3NXAU9C2dKj8+/rP75Qs/CXvnz59dmAwcO1GZVqlTRZgEBAdqsWLFi2uy3337TZitXrtRmc+bM0Wauwp6e5ckiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMHs4uICOZLaNrZunSpQ6twxmCgoK02fDhw7XZ7t27tVmDBg3SUhKQ6QwZMkSbzZ07V5s1atRIm5ktyWmV2VLbX375pTZ7/vnntVlkZGSaagKc4dVXX9VmZsva5syZU5vduXNHm505c0abhYSEaDMz9+7d02bBwcHaLCoqSps1bdpUm509e9auuoCszt/f3+Hn3LJli8PPCWRWpUqV0mazZ8/WZs2bN9dmefPmTUtJqTJbIr5u3brarHbt2pauZ/b9h6vhySIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMDAsAgAAAAAAgIFhEQAAAAAAAAwezi7A0Tp27KjNlixZYumc0dHR2mz9+vWWzpnRWrdurc3MlhNMTExMj3KATKlGjRraLEeOHNrMbCn73377LU01pWbatGna7IknntBm48eP12YtW7ZMU01Aepk+fbo2e+utt7TZ0aNHtVlYWJg2++6777TZrl27tJlVbm76f7d77733tFmZMmW0WYkSJbTZ2bNn7aoLyOr8/f0dfs7IyEiHnxNwplq1amkzs5+DixUrps1sNps2M/u59MqVK9rs3r172uzChQvarGLFitrMx8dHm/Xs2VObubu7a7Pg4GBtZnZ/zsKTRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGDycXYCjeXjob8lseVoz7777rjYzWzIQQOZTrVo1bfbKK69YOmd0dLTVcgCISJEiRbTZqFGjtJnZ67rZsrYHDx60r7AM0Lp1a0vH7d+/X5udPHnSajlAtjFhwgRLx23ZskWbTZw40VoxgBP5+flps9DQUG1WrFgxh9cyduxYbbZgwQJtFhsbq83efvttbWa1Z83eZ0WLFtVmhw4d0mY//vijpVrSE08WAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABg0K8zD8MTTzzh7BKc5sknn9RmZsslnj9/Pj3KAdLMbDlLT09PS+c0W64TwKPZbDZt5uZm7d+1lFJWy3G4UqVKaTOrSw9/9dVX2uzvv/+2dE4gq0mPpewjIyMdfk7Amd5//31tVqZMGUvnDA0N1WYvvPCCpXOaMVvKftCgQdrM6vf+586d02bNmjXTZidOnLB0PWfhySIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMDAsAgAAAAAAgIFhEQAAAAAAAAwezi7ACrOlr996660MrCRzad++vTYrXbq0pXOWL19em9WvX1+bhYWFWboe4AgeHvovbWPGjLF0zrt372qzM2fOWDongOzh22+/1WYlSpTQZhcuXNBm3333XZpqAgBkH/ny5dNmLVu21GZKKW22cuVKbTZgwAD7CnsMXbp00WYffvihNitTpow2M7s/s+/9x48fr81OnDihzVwNTxYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMDAsAgAAAAAAgIFhEQAAAAAAAAwMiwAAAAAAAGDQry/toooXL+7sEpzm1KlT2uzGjRvazMvLKz3KAZymUaNG2qx58+aWzjlnzhxtFhkZaemcZszuoVq1apbOuWfPHqvlAOkqf/78Dj/niBEjtNnAgQMtndPb21ubff3119qsRo0alq63ePFibXbo0CFL5wSykwkTJjj8nFu2bHH4OQFnMns9qVq1qjabN2+eNouPj7dUy7vvvqvNxo4dq83S4+dZs9fg4OBgh18vM+LJIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAgWERAAAAAAAADB7OLsCKCxcuaLMlS5Zos//+97+WrpczZ05tVrlyZW32999/a7OrV69aOqeZjz76SJsVKFDA0jkBV9SwYUOHn/PDDz90+Dlz5MihzcaPH6/NPDz0X7rv3r2rzX788Uf7CgMy2PXr17XZyZMntVnZsmW1WbVq1dJUU2p69OihzTp06GDpnFeuXNFm69ats3ROIDuZOHGiw8+5ZcsWSxmQWZn97LlmzRptVrVqVW22cOFCbebn52fpuH79+mkzs5/Jrfrkk0+02Xvvvefw67kaniwCAAAAAACAgWERAAAAAAAADAyLAAAAAAAAYGBYBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMCgX3/ZRR0+fNjh53zqqae02aFDh7TZrl27tNmff/6pzV5++WVtlpiYqM0A3FehQgWHn7Nz587aLDY2VptFRUVpsxMnTmizVq1a2VNWCgsWLNBmERERls4JpLfTp09rsz/++EOblS1bVpvVrVtXm9WvX1+bmb0+v/LKK9rMzPXr17VZw4YNtdnx48ctXQ/ITiZMmODwc0ZGRjr8nEBmZbZ8fI8ePbRZnTp1tFlm+pl1yJAh2szs3sGTRQAAAAAAAHgAwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMDAsAgAAAAAAgMHD2QU42r1797RZQkKCNnN3d3d4LWZL85plVt29e1ebmd2fmxszQ7ieUaNGabOXX37Z4ddbvHixpeN+//13bVaoUCGr5WhVrVpVm1WuXFmbHT161OG1AI4QGBiozf744w9tVrx4cW0WHByszW7cuKHNnn76aW0WExOjzZ5//nltdvz4cW0G4D5/f/8Mvd7EiRMz9HqAM50/f16b9e/fX5vt2LHD0vVsNps2U0pps9OnT2uzLl26aLN9+/bZVRdSYkoAAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAIDBpszWp3twR5Ml7lxF3759tVm9evW02dChQ9OjHC2zpey3bdumzWbMmKHNPvjgA21WqVIl+wp7SLdu3bRZWFiYpXO6CjvbxqmyQs9atWfPHm1Wp06dDKwkczHr2bVr12ZgJRmPns2aXn31VW320UcfaTN3d3dL17tx44Y269SpkzbbsmWLpetlZ/QsHhQREaHN/P39LZ3TrC+bN29u6ZzZGT3rujw9PbVZcHCwNnvhhRcsXc/s42D2eWTWl1u3brVUS3ZmT8/yZBEAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAYPZxeQkb744gtL2euvv54e5WSomTNnajOWkURWExoaqs3q1KmTgZVkvMuXL2szlu9GVrNw4UJt1rFjR23Wpk0bS9cbM2aMNqO/gLSZOHGiNvP397d0TrO+NFuGG8hO+vfvr81eeOGFDKzEXGBgoDbbunVrBlaSffBkEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABg9nF4CMoZSylAGuKCgoSJvt2LFDm8XFxWmzFi1aaLNPPvlEm5ktOWq27LdV4eHh2uzq1asOvx6QWe3Zs0ebtWnTxtI5zZb2Xr58uTa7fv26pesB2UmzZs0cfs7IyEiHnxNwRX369NFmCxYscPj1QkNDtdm8efO02XfffafNXnvtNUvHbdq0SZvBHE8WAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABg8HB2AcgYM2bM0Gaff/55BlYCpL/bt29rs61bt1o652+//WbpuLi4OEvHmTly5Ig2+7//+z+HXw9wJk9PT222aNEibRYYGKjNvv32W23WsmVLbZY/f35ttnbtWm3Wvn17bWb29QrIaiIiIrSZv7+/w6+3ZcsWh58TyKxKlSqlzcaMGWPpnEopbbZy5UptNmDAAG0WHx+vzS5cuKDNnnjiCW1Wt25dbbZp0yZtBnM8WQQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMDAsAgAAAAAAgMHD2QUgY1y/ft3ZJQBwEA8P/Zdum82WgZUAjuHp6anNtm3bps38/Py02dy5c7XZyJEjtVmXLl202Zo1a7RZ8+bNtVmuXLm02e3bt7UZkNX4+/s7/JxbtmyxlAFZzcsvv6zNKlWqZOmcv//+uzYbNGiQNouPj7d0vfXr12szs3vo1q2bNpsxY4alWsCTRQAAAAAAAHgAwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMDAsAgAAAAAAgEG//jKyFLOlQw8fPqzNqlatqs1effVVbRYWFmZPWUCWN2TIEIefc/Dgwdrszp07Dr8ekN66du2qzfz8/LSZ2WvN1KlTLdVy8uRJS8eZ6dGjhzZbuHChw68HOFNERESGXq958+YZej0gszJbPt7MuXPntFmvXr202a1btyxdLz3ky5fP2SVkSTxZBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAwcPZBSBjXL16VZvFxcVZOmeJEiWslgNkGx4e1r7M2mw2bebv76/NtmzZYul6QHpzc9P/+9TEiRO12Y8//qjNXn/9dW125coVbVa+fHltNnr0aG1m1dmzZx1+TsCZzHrW7DUKQPox+97RLDt8+LA2O3r0aJpqSk3+/Pm12YABA7SZ2T2sWbMmTTUhdTxZBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAwdqazgCAdKWU0mZhYWEZVwjgIM8884w2q1ChgjYLDg7WZlWqVNFmvXv31mbvv/++NrNq/fr12mzjxo0Ovx6QnUyaNMnZJQCZ3p49e7RZjRo1tJmvr682q1Wrljbz8vLSZt26ddNmAwYM0GZ58+bVZmbfG//000/aDNbxZBEAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAYPZxcA51u9erU2q1evnjbz8NB/+vj4+GizuLg4+woDXET9+vW12dNPP52BlQCZl9mSvidOnNBm06ZNS49ytP78809tFhwcrM0++ugjbXbnzp001QRkB1u2bLGUAbhv2bJl2uyZZ57RZg0bNtRme/fuTVNNqbHZbNpMKaXNzp49q81OnTqVppqQOp4sAgAAAAAAgIFhEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAYFNm69M9uKPJEndwbQEBAdosPDzc0jn79eunzZYvX27pnJmJnW3jVPRsxsmXL582W7VqlTZr2bKlNjt06JA2a9y4sTaLiYnRZtkZPZu5TZs2TZv16dNHmxUvXlybrV27Vpt988032sxsie5z585pMzgWPQu4Fno2cytatKg2e//997VZYGCgNvPy8rJUy44dO7TZ6tWrtdnnn3+uzWJjYy3Vkp3Z07M8WQQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMDAsAgAAAAAAgMGm7FznMDsvNZjVBQQEaLPw8HBtdvnyZUvnPHjwoH2FZWIsDwp7mS37vWjRIm327rvvarOgoKC0lJQt0bOAa6FnAddCzwKuxZ6e5ckiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMNmXnOocsNQj8i+VBAddCzwKuhZ4FXAs9C7gWe3qWJ4sAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAabUko5uwgAAAAAAABkDjxZlEmsWLFCoqKijP9funSpnDt3znkFATBFzwKuhZ4FXAs9C7gWejbrSddhkc1ms+tty5Yt6VmGS/j5559l9OjREhUVJeHh4TJs2DBxc2OWl1ZTp06VTp06SeHChcVms8nEiROdXVKmRs/aj551vKNHj8ro0aOldu3akjt3bilatKi0b99efvvtN2eXlmnRs/ajZx3v/Pnz8tJLL0mlSpUkd+7ckjdvXqlfv7588cUXwoPrqaNn7UfPpr+QkBCx2Wzi6+vr7FIyLXrWfvSs40VFRWk/57766qt0v75Hep58+fLlyf5/2bJlsmnTphTbq1Spkp5luISRI0eKv7+/lC1bVkRE/vOf/0jRokWdXJXre++996RIkSJSp04dCQ8Pd3Y5mR49az961vE+/fRT+eyzz6Rbt24ydOhQiYmJkcWLF8szzzwjGzZskICAAGeXmOnQs/ajZx0vOjpazp49K4GBgVKqVCm5e/eubNq0Sfr16yd//PGHTJs2zdklZjr0rP3o2fR148YNGT16tOTKlcvZpWRq9Kz96Nn007NnT2nXrl2ybQ0bNkz362bo3yx67bXXZP78+fxrk8bNmzfl4MGDUqBAASlXrpyzy8kSoqKipEyZMhIdHS0FCxaUCRMm8HTRY6BnzdGzjrVnzx6pVKlSsn/hvHLlilSpUkUqVqwo27Ztc2J1roGeNUfPZoyOHTtKRESExMTEiLu7u7PLydToWXP0bPp55513JCwsTOrVqydhYWFy48YNZ5fkEuhZc/SsY0VFRUnZsmVl5syZ8tZbb2X49TPVc2F37tyRCRMmSPny5cXT01NKliwpo0ePljt37qTYd8WKFVK/fn3x8fGRfPnySdOmTWXjxo0iIlKmTBnTxwTLlCljnOfmzZvy5ptvSsmSJcXT01MqVaoks2bNSvEF4MHj3d3dpXjx4jJo0CC5du2asc+WLVvEZrPJ6tWrtffYr1+/ZNdPerRs6dKlkitXLmnQoIGUK1dOhg0bJjabTfr162f6PjN7NM1ms4m/v3+K+r7++msZO3asFClSRHLlyiWdOnWSM2fOJDuvv79/smNFRHbv3m2cN7X3TVBQUIr6KleuLDabTV577bVk269duyYjRoww3u/ly5eXGTNmSGJiYop7mzVrlsyZM0dKly4t3t7e0qxZMzl48KDp+yXJg+9rOB49S886smf9/PxSPAqfP39+adKkiRw5cuSRx+PR6Fl61tGvs6kpU6aMxMXFSXx8vOVz4D56lp5Nj549duyYzJkzR2bPni0eHun6iybZDj1Lz6bX6+zNmzcz/HU103x1SExMlE6dOsm2bdtk0KBBUqVKFTlw4IDMmTNH/vzzTwkLCzP2nTRpkkycOFGeffZZ+e9//ys5c+aUX3/9Vf7f//t/0rp1awkKCjKm40eOHJFp06bJ2LFjjccDk34YUUpJp06dJCIiQgYMGCC1a9eW8PBwGTVqlJw7d07mzJmTrMYuXbpI165d5d69e/LLL7/IJ598Irdu3UrxGGJaHT9+XJYsWfJYx6T2aNqYMWNS3Xfq1Klis9nk7bfflkuXLklQUJAEBATIvn37xNvbW3uNt99+W5t5eXlJcHCwjBgxwti2Y8cOOXXqVIp94+LipFmzZnLu3DkZPHiwlCpVSnbs2CFjxoyRCxcupGjSZcuWSWxsrAwbNkxu374tc+fOlRYtWsiBAwekcOHC2pqQvujZf9GzQcn2d3TPXrx4UQoUKPDYxyE5evZf9GxQsv3T2rO3bt2Smzdvyo0bNyQyMlKCg4OlYcOGpveKR6Nn/0XPBiXbP609O2LECGnevLm0a9dOVq1a9cj9YR969l/0bFCy/dPas5MmTZJRo0aJzWYTPz8/mTp1qrRu3fqRx6WZykDDhg1TuksuX75cubm5qZ9//jnZ9kWLFikRUdu3b1dKKXXs2DHl5uamunTpohISEpLtm5iYmOK8ERERSkRUREREiiwsLEyJiJoyZUqy7YGBgcpms6njx48b20RETZgwIdl+zz77rKpatWqKa4WGhqZ6j0op1bdvX1W6dGnj/0+ePKlERAUHBxvbevTooapXr65Kliyp+vbtqz3Xg8fPnDkzRVatWjXVrFmzFPUVL15cXb9+3di+atUqJSJq7ty5xrZmzZolO/aHH35QIqLatGmT4mMoIiowMFB5eHio3377zdg+YMAA1atXLyUiatiwYcb2yZMnq1y5cqk///wz2Xneeecd5e7urk6fPp3s3ry9vdXZs2eN/X799VclImrkyJGm75sHXb58OdWPIczRs/SsUs7p2SRbt25VNptNjRs37rGPzY7oWXpWqYzv2enTpysRMd5atmxpXAPm6Fl6VqmM7dn169crDw8PdejQIaXU/fd/rly5Hnkc7qNn6VmlMq5nT506pVq3bq0WLlyovv32WxUUFKRKlSql3Nzc1Pr1602PdYRM82tooaGhUqVKFalcubJER0cbby1atBARkYiICBERCQsLk8TERBk/fnyKv67+8ONkj/LDDz+Iu7u7DB8+PNn2N998U5RS8uOPPybbHhcXJ9HR0XLx4kVZs2aN/P7779KyZcsU542NjZXo6Ohkj/TZa8+ePRIaGirTp09Pt78e//LLL0vu3LmN/w8MDJSiRYvKDz/8kOr+SikZM2aMdOvWTRo0aJDqPoULF5b27dtLcHCwiNx/X61atUr69++fYt/Q0FBp0qSJ5MuXL9nHOiAgQBISEmTr1q3J9u/cubMUL17c+P/69etLgwYNtPUiY9Cz99Gz6dezly5dkl69eknZsmVl9OjRj3UsUqJn76NnHd+zPXv2lE2bNsnKlSulV69eInL/aSOkDT17Hz3ruJ6Nj4+XkSNHypAhQ6Rq1aqm++Lx0bP30bOO69lSpUpJeHi4DBkyRDp27ChvvPGG/O9//5OCBQvKm2++aXqsI2SaYdGxY8fk0KFDUrBgwWRvFStWFJH7PzSIiPz111/i5ubmkC9wp06dkmLFiiX7RBP596/ZP/zI2cyZM6VgwYJStGhRCQwMlCZNmsiMGTNSnPeVV16RggULSr58+SR37tzSq1cv+fvvv+2q6Z133pEmTZpIhw4dLN7Vo1WoUCHZ/9tsNilfvrxERUWlun9ISIgcOnTokaua9O/fX1auXCl37tyR0NBQyZcvn/HF8UHHjh2TDRs2pPhYJ610lPSx1tUrIlKxYkVtvcgY9Ox99Gz69OzNmzelQ4cOEhsbK+vWrWNZXwegZ++jZx3fs6VLl5aAgADp2bOnhISEyFNPPSUBAQEMjNKInr2PnnVcz86ZM0eio6Nl0qRJpvvBGnr2Pno2fX+effLJJ6V///7yxx9/yNmzZx/7+MeRqf5mUY0aNWT27Nmp5iVLlszgilLq06ePvPzyy5KYmCgnTpyQyZMnS4cOHWTz5s3JpsDjx4+XJk2ayN27d2XPnj3y3//+V65du/bIyeHGjRtl8+bN8ssvv6T3rdgtPj5exo0bJwMGDDC+0Om0b99ecubMKWFhYRIcHCx9+/ZNdZqcmJgorVq10j4p8KjrIHOgZ+nZJI7u2fj4eOnatavs379fwsPDpXr16g49f3ZFz9KzSdL7dTYwMFCWLFkiW7duleeeey5dr5WV0bP0bBJH9GxMTIxMmTJFhg4dKtevX5fr16+LiMiNGzdEKSVRUVHi4+MjhQoVSvO1sit6lp5Nkt6vs0mfS//884+UKFEi3a6TaYZF5cqVMx6DM3v8rly5cpKYmCiHDx+W2rVrp+mapUuXls2bN0tsbGyyaezRo0eN/EFJ/1KWJE+ePNKrVy/ZuXOnNGzY0Nheo0YNY7+2bdvK6dOn5YsvvpB79+5pa1FKyTvvvCNdunSRZ555Jk339SjHjh1Lce3jx49LzZo1U+y7YMECuXTpkl3LzXt4eEifPn1k6tSpcujQIfn8889T3a9cuXJy48aNZO/Lx6lXROTPP/9kpTMno2fpWXvrFbG/ZxMTE+Xll1+Wn376SVatWiXNmjWz65p4NHqWnrW3XpG0vc4mPVEUExNj6XjcR8/Ss/bWK/Lonr169arcuHFDPvjgA/nggw9S5GXLlpXnn38+2R9hxuOhZ+lZe+sVSdvr7IkTJ0REpGDBgpaOt1em+TW0Hj16yLlz51L9q+lJq2yI3P99Pzc3N/nvf/+bbFk6EUmxPOCjtGvXThISEuTjjz9Otn3OnDlis9mkbdu2pscnfTOU2lKID0pMTBQ3NzfTLxpfffWV7N+/X6ZPn25n9dYl/TX2JKtXr5YLFy6kuN/Y2FiZOnWqjBw5UooUKWLXuV955RU5cOCANG3aVJ566qlU9+nRo4f88ssvEh4eniK7du1aii9CYWFhcu7cOeP/d+3aJb/++usjPz5IX/QsPSvi+J59/fXX5euvv5YFCxZI165d7boH2IeepWdFHNuzly9fTnX7Z599JjabTerWrfuo24EJepaeFXFczxYqVEjWrl2b4q158+bi5eUla9eu1a48BfvQs/SsSPq/zp47d04+//xzqVmzphQtWtSeW7Is0zxZ1KdPH1m1apUMGTJEIiIipFGjRpKQkCBHjx6VVatWSXh4uNSrV0/Kly8v7777rkyePFmaNGkiXbt2FU9PT9m9e7cUK1bssT45O3bsKM2bN5d3331XoqKipFatWrJx40ZZt26djBgxQsqVK5ds//3798uKFStEKSV//fWXfPTRR1KiRAmpV69esv327dsnvr6+cu/ePdmzZ48sW7ZMnn/+eXF3d9fWsnHjRhk4cKBUqlTp8d5xFjz55JPSuHFj6d+/v/z9998SFBQk5cuXl4EDBybbb+/evVKgQIHH+sOyVapUkejoaNMlC0eNGiXffvutdOjQQfr16yd+fn5y8+ZNOXDggKxevVqioqKSLZNdvnx5ady4sbz66qty584dCQoKkvz589tV1/Lly+XUqVMSFxcnIiJbt26VKVOmiMj9z7mHp+2wHz1Lzzq6Z4OCgmTBggXSsGFD8fHxkRUrViTLu3TpIrly5bL73pAcPUvPOrpnp06dKtu3b5c2bdpIqVKl5J9//pE1a9bI7t275fXXX5fy5cvbfV9IiZ6lZx3Zsz4+PtK5c+cU28PCwmTXrl2pZng89Cw96+jX2dGjR8tff/0lLVu2lGLFiklUVJQsXrxYbt68KXPnzrX7nixL9/XWHmC21KBSSsXHx6sZM2aoatWqKU9PT5UvXz7l5+enJk2apGJiYpLt+/nnn6s6deoY+zVr1kxt2rQpxTnNlhpUSqnY2Fg1cuRIVaxYMZUjRw5VoUIFNXPmzBTLFsoDS8LabDZVpEgR1bVrV3XkyJEU10p68/DwUKVLl1bDhw9XV69eVUrplxr09vZW586dS3bN0qVLp8tSg19++aUaM2aMKlSokPL29lbt27dXp06dSnZss2bNlIioOXPmJNs+YcKEVJcafHApwYellsfGxqoxY8ao8uXLq5w5c6oCBQqoZ599Vs2aNUvFx8enuLcPP/xQlSxZUnl6eqomTZqo33//3fT98vB9pPam+5zAv+hZejZJRvRs3759tf0qIurkyZOPPEd2R8/Ss0kyomc3btyoOnToYHxsc+fOrRo1aqSCg4NTXf4ZKdGz9GySjPre+GF9+/ZVuXLlsnRsdkTP0rNJMqJnV65cqZo2baoKFiyoPDw8VIECBVSXLl3Unj17HnmsI9iUesxn3eCytmzZIs2bN5fQ0FAJDAx0djmPFBUVJWXLlpWZM2fKW2+95exygAxHzwKuhZ4FXAs9C7gWejZjZZq/WQQAAAAAAADnY1gEAAAAAAAAA8MiAAAAAAAAGPibRQAAAAAAADDwZBEAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiE0uXLhWbzSY2m022bduWIldKScmSJcVms0mHDh2cUGH6i4uLk/nz50vr1q2laNGikjt3bqlTp44sXLhQEhISnF0ekAw9e19iYqIsWrRIateuLb6+vlK4cGFp27at7Nixw9mlAcnQs/f5+/sb74cH39q0aePs0oBk6Nl/xcfHy7Rp06Ry5cri5eUlhQsXlvbt28vZs2edXRpgoGfv43XWGg9nF+AKvLy8ZOXKldK4ceNk2yMjI+Xs2bPi6enppMrS34kTJ+T111+Xli1byn/+8x954oknJDw8XIYOHSo7d+6UL774wtklAilk554VERk1apTMnj1bXnrpJRk6dKhcu3ZNFi9eLM2aNZPt27dL/fr1nV0ikEx271kRkRIlSsj06dOTbStWrJiTqgHMZfeevXv3rrRv31527NghAwcOlJo1a8rVq1fl119/lZiYGClRooSzSwSSye49K8LrrBUMi+zQrl07CQ0NlY8++kg8PP59l61cuVL8/PwkOjraidWlryJFisiBAwekWrVqxrbBgwfLK6+8IsHBwTJu3DgpX768EysEUsrOPXvv3j1ZuHChBAYGyvLly43t3bt3l6eeekpCQkIYFiHTyc49myRPnjzy0ksvObsMwC7ZvWfnzJkjkZGRsm3bNl5T4RKye8+K8DprBb+GZoeePXvKlStXZNOmTca2+Ph4Wb16tfTq1SvVYxITEyUoKEiqVatmPJo6ePBguXr1qrFPmTJlUn0cLumtTJkyIiISFRUlNptNli5dahwbGxsrfn5+UrZsWblw4YKxfdasWfLss89K/vz5xdvbW/z8/GT16tUp6ouOjpajR49KXFyc6b0XKFAg2aAoSZcuXURE5MiRI6bHA86QnXv27t27cuvWLSlcuHCy7YUKFRI3Nzfx9vY2PR5whuzcsw+6d++e3Lhxw+79AWfJzj2bmJgoc+fOlS5dukj9+vXl3r17j9XngDNk5559EK+zj4dhkR3KlCkjDRs2lC+//NLY9uOPP0pMTIy8+OKLqR4zePBgGTVqlDRq1Ejmzp0r/fv3l5CQEHnuuefk7t27IiISFBQky5cvl+XLl8vYsWNFRGTs2LHGtqCgoFTPfffuXenWrZucPn1awsPDpWjRokY2d+5cqVOnjvz3v/+VadOmiYeHh3Tv3l2+//77ZOf4+OOPpUqVKrJr1y5L75OLFy+KyP1hEpDZZOee9fb2lgYNGsjSpUslJCRETp8+Lfv375d+/fpJvnz5ZNCgQY98/wEZLTv3bJI///xTcuXKJblz55YiRYrIuHHjjPsAMpvs3LOHDx+W8+fPS82aNWXQoEGSK1cuyZUrl9SsWVMiIiIe+b4DnCE792wSXmctUNAKDg5WIqJ2796tPv74Y5U7d24VFxenlFKqe/fuqnnz5koppUqXLq3at29vHPfzzz8rEVEhISHJzrdhw4ZUtyulVEREhBIRFRERkSI7efKkEhEVHBysEhMTVe/evZWPj4/69ddfU+ybVF+S+Ph4Vb16ddWiRYtk2ydMmKC93qPcuXNHVa1aVZUtW1bdvXv3sY8H0gs9e9+xY8dU3bp1lYgYb0899ZQ6evToI48FMhI9e98rr7yiJk6cqNasWaOWLVumOnXqpERE9ejR45HHAhmJnlXqm2++USKi8ufPrypUqKCCg4NVcHCwqlChgsqZM6f6/fffTY8HMhI9ex+vs9bwZJGdevToIbdu3ZL169dLbGysrF+/XvvIXmhoqOTJk0datWol0dHRxpufn5/4+vqm6V8dRo0aJSEhIbJq1apUf0f6wV8xuXr1qsTExEiTJk1k7969yfabOHGiKKXE39//sWt47bXX5PDhw/Lxxx8n+51XIDPJzj2bO3duqVatmgwbNky++eYbWbBggdy7d086d+6cLX4nHa4pO/fsZ599JhMmTJCuXbtKnz59ZN26dTJw4EBZtWqV7Ny50/K9AOkpu/Zs0q+wxMbGyk8//ST9+vWTfv36yebNm0UpJR988IHlewHSU3btWRFeZ63iJ307FSxYUAICAmTlypUSFxcnCQkJEhgYmOq+x44dk5iYGClUqFCq+aVLlyzVsHjxYuOT+cHfFX3Q+vXrZcqUKbJv3z65c+eOsd1ms1m65sNmzpwpS5YskcmTJ0u7du0cck4gPWTXnr13754EBASIv7+/zJs3z9geEBAg1apVk5kzZ8qMGTMsnRtIT9m1Z3XefPNNWbJkiWzevFmeeeYZh54bcITs2rNJP8g2atRISpYsaWwvVaqUNG7cWHbs2GHpvEB6y649q8Pr7KMxLHoMvXr1koEDB8rFixelbdu2kjdv3lT3S0xMlEKFCklISEiqecGCBS1df+fOnTJ16lTZvXu3jBw5Utq0aZPsbwb9/PPP0qlTJ2natKksWLBAihYtKjly5JDg4GBZuXKlpWs+aOnSpfL222/LkCFD5L333kvz+YD0lh17duvWrXLw4EGZPXt2su0VKlSQKlWqyPbt2y2dF8gI2bFndZJ+CP3nn38cel7AkbJjzyYttf3wQhIi9xeT+N///mfpvEBGyI49q8Pr7KMxLHoMXbp0kcGDB8vOnTvl66+/1u5Xrlw52bx5szRq1MihKw+98sorMnbsWDl//rxUrVpVRo4cmWxp7DVr1oiXl5eEh4eLp6ensT04ODjN1163bp383//9n3Tt2lXmz5+f5vMBGSE79uzff/8tIiIJCQkpsrt378q9e/csnxtIb9mxZ3VOnDghIta/IQcyQnbs2Ro1akiOHDnk3LlzKbLz58/Ts8jUsmPP6vA6+2j8zaLH4OvrKwsXLpSJEydKx44dtfv16NFDEhISZPLkySmye/fuybVr1yxdv0mTJiJy/180ZsyYIStWrJCNGzcaubu7u9hstmQ/JEZFRUlYWFiKcz3OUoNbt26VF198UZo2bSohISHi5sanDVxDduzZihUriojIV199lWz73r175Y8//pA6depYuhcgI2THnr1+/Xqyx+xFRJRSMmXKFBERee655yzdC5ARsmPP5s6dW9q1ayc7duyQo0ePGtuPHDkiO3bskFatWlm6FyAjZMee5XXWOp4sekx9+/Z95D7NmjWTwYMHy/Tp02Xfvn3SunVryZEjhxw7dkxCQ0Nl7ty52t8PtdegQYNk5cqVMmTIEDl48KD4+PhI+/btZfbs2dKmTRvp1auXXLp0SebPny/ly5eX/fv3Jzv+448/lkmTJklERITpHwU7deqUdOrUSWw2mwQGBkpoaGiyvGbNmlKzZs003QuQnrJbz/r5+UmrVq3kiy++kOvXr0vr1q3lwoULMm/ePPH29pYRI0ak6T6A9Jbdenbv3r3Ss2dP6dmzp5QvX15u3bola9eule3bt8ugQYOkbt26aboPIL1lt54VEZk2bZr89NNP0qJFCxk+fLiIiHz00Ufy5JNPGsuHA5lVdutZXmetY1iUThYtWiR+fn6yePFiGTt2rHh4eEiZMmXkpZdekkaNGqX5/DabTZYsWSK1atWS9957T2bPni0tWrSQzz77TN5//30ZMWKElC1bVmbMmCFRUVEpmsteJ0+elJiYGBERGTZsWIp8woQJDIuQJWSVnhW5/2ujs2bNkq+++ko2bNggOXPmlCZNmsjkyZOlUqVKab4XIDPIKj1bunRpadKkiaxdu1YuXrwobm5uUqVKFVm0aJEMGjQozfcBZBZZpWdFRKpWrSqRkZHy9ttvy5QpU8TNzU1atGghM2fOlOLFi6f5XoDMIKv0LK+z1tmUUsrZRQAAAAAAACBz4I/PAAAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAg4e9O9pstvSsA3ApSilnl/BI9CzwL3oWcC30LOBa6FnAtdjTszxZBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAgWERAAAAAAAADAyLAAAAAAAAYGBYBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAgWERAAAAAAAADAyLAAAAAAAAYGBYBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDg4ewCAAAAAECndevW2uydd97RZs2bN9dmO3bs0GbTp0/XZuvXr9dmAJCV8GQRAAAAAAAADAyLAAAAAAAAYGBYBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGm1JK2bWjzZbetQAuw862cSp6FvgXPQu4Fno2a8qXL582GzJkiDYbP368NsuRI4c2M/sYmX2O3b17V5vVqFFDmx0/flybZXX0LOBa7OlZniwCAAAAAACAgWERAAAAAAAADAyLAAAAAAAAYGBYBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDg4ewCHM3DQ39Lvr6+2uw///mPNsuTJ482Gz58uDYzW47O6lKeZpYtW6bNTp8+bemcixcv1mbnz5/XZq6wfCbwON566y1t5uaWsXP3n376SZvt2bNHm40cOVKbjRs3Tptdu3ZNm7Vq1Uqb/fXXX9oMeFCZMmW0WZEiRRx+vZ07dzr8nAAerU2bNtps8uTJGViJuRw5cmgzd3f3DKzEnFmdPXv21GZmPzMADzLr2e+//16bNW/eXJtt3bo1TTUh4/BkEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABpuyc41zs6XeM5qPj482M1tSun79+ulRjiWJiYna7Pbt29rM7N4zWs2aNbXZoUOHMrCSjGdn2zhVZurZjPbEE09os5CQEG32zDPPaLP8+fOnqSZHunnzpjYz+/qRHvfQsWNHbWa2pGpGo2czt3PnzmmzwoULO/x6u3bt0mZ79uzRZseOHdNmFy5csFRLdHS0NouIiLB0zqyAnnVdL774ojZbtGiRNvP19XV4LWYfo3fffVebrV27VpudPHlSm8XHx9tXmIOYfb/zzz//aDMPDw+H10LPuq7KlStrs8jISG1m9n3lmTNntJnZ696SJUu0mZmCBQtqs86dO1s6Z3owu79vvvlGm5m9z6yyp2d5sggAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAgWERAAAAAAAADAyLAAAAAAAAYGBYBAAAAAAAAINN2bnOYWZaanDnzp3a7Omnn9ZmZrd69epVS7WEhYVps4MHD2qzS5cuabMtW7Zosx49ethTVgr9+/fXZlWrVtVm7u7u2mz58uXarF+/fnbV5apYHtT5evbsqc0mT56szZ566qn0KCdLM1t+t02bNtrst99+S49yLKFnnW/hwoXabNCgQdosPT52Zu/rjL7enTt3tNn27du12Q8//KDN5syZY19hmRg967o2btyozVq0aJGBlYg888wz2ux///ufNktISEiPchzuiSee0GZmr90eHh4Or4WezZrMfmbNnz+/NrP6Ousqx7m56Z+5SUxMtHSc2ffU4eHh2swqe3qWJ4sAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADDYlJ3rHGampQbPnz+vzcyWgnz77be1WXBwcJpqcmV79uzRZrVr19Zmy5cv12b9+vVLQ0WZH8uDOt/WrVu1WePGjR1+vV27dmmzKVOmaLNr165Zul6HDh20Wbly5bRZt27dLF3PTK9evbTZV1995fDrpQd6NmOYvWZERkZqM7Pln82WoLXK6lK5Wf16Zv28atUqbbZu3Tr7CnsM9Gzm1qlTJ2322WefabN8+fJZup7ZUvbTp0/XZhMnTrR0PVdh9rXzn3/+0WZmPy9ZRc9mTX///bc2y58/vzbL6KXss8Jxn3zyiTZ79dVXtZlV9vQsTxYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMDAsAgAAAAAAgIFhEQAAAAAAAAwMiwAAAAAAAGBw/LqJGaBkyZLarFq1atps//796VEOgCziyy+/1GZ9+vTRZumxtPfTTz+tzbp16+bw633//ffabOPGjQ6/HrKmESNGaLNcuXJpM7MeyujlmLPz9V544QVtVrRoUW22bt26NNWEzOmZZ57RZp9//rk2y5s3r8NriYqK0mYTJ050+PUA3FewYEFtZnWJ+OjoaG125coVbVapUiVL1zNj9Tg3N/0zN4cPH9Zmp0+f1mYhISGWaklPPFkEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAIDBw9kFWJGQkKDN9u/fn4GVuI7mzZtrs9KlS1s6J0vlwplu377t8HNWqFBBm3l7e2uzmzdvWrpe+fLltdnQoUO1Wbly5Sxdb+vWrdqsd+/e2uz69euWroesKX/+/NqsQYMGDr/eN998o81mz57t8OtlBblz59ZmRYoU0WbHjh3TZhcuXEhTTXA9ZstU582b1+HXu3r1qjbr1KmTw68HZCcFCxbUZmPGjNFmSilLmZk+ffpos23btmmzypUrW7peRjt69Kg2i4uLy8BK0o4niwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMHg4uwA4jq+vrzabM2eONsuXL582i4mJ0WZ79uyxrzAgHYwfP16bBQQEWDpnvXr1tNnUqVO12YgRI7TZa6+9ps3+85//aLMyZcpoMzNbtmzRZjNnztRm169ft3Q9ZD8vvviiNqtQoYLDr3fz5k1t1rBhQ222d+9ebRYZGZmmmoCsomnTptrsww8/dPj1EhMTtdmKFSu02R9//OHwWrKC27dva7NNmzZlYCXI7Pz8/LTZG2+8oc1sNpul65kdZ/Zz6fTp07XZN998o81cbUl6V8GTRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGGxKKWXXjhaXzUPGadWqlTbbsGGDpXMGBgZqs7Vr11o6Z1ZgZ9s4VVbvWTc3/ax7zZo12uz555+3dD2z5X4TEhK0mYeHhzaz+jH66aeftFmbNm20mVmdWR096zhmy+9u27ZNm+XMmVObmd17enzsbt68qc3Wr1+vzV544QVttnfvXm1m9vocHx+vzbLzUsD0bMY4ffq0NitWrJjDr3fkyBFtVqNGDYdfLz2MHDlSm12/fl2bffbZZw6vxcvLS5tt2rRJmzVp0sThtdCzmVtkZKQ2a9SokTaz+vqcHseZ/exp9jMrUmdPz/JkEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABpuyc53D7LzUYGZSvXp1bfbpp59qs6efflqb7dixQ5u1a9dOm8XGxmqzrI7lQTO3J598Upv1799fm82cOTM9yrHk1q1b2qxr167aLDw8PD3KcXn0bMYYMmSINps9e7Y28/T01Gbp8bGzuqSvVcePH9dm8+fP12bz5s1zeC2ugp51HD8/P232008/abPcuXM7vJZFixZps2HDhjn8emPGjNFmDRo00GYdO3Z0eC1mVqxYoc3Mvjc5ffq0Nrt69ao2c3d3t6+wx0DPOt+gQYO0mVnvWV3K3uy4vXv3arPKlStrs1y5clm6XlhYmDbr06ePNouLi9NmWZ09PcuTRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGGzKznUOs/pSg5nJE088oc0+/fRTbdatWzdt9s8//2iz3r17a7ONGzdqs+yM5UFdl9mSnPv379dmZcuWTY9ytL744gttNmHCBG1mtoxudkbPOl/dunW12ejRoy2ds0WLFtrsySef1GZWlwK2yux6sbGx2mzevHnabNy4cWmqKbOjZx+Pn5+fNtu8ebM2y507t8Nr+fjjj7XZW2+9pc38/f0tHffMM89oM7P7c4XPMRGRkydPajOzj7vZ9/4eHh5pqik1rvD+zEw9mx4aN26szSIjI7WZ2cfuypUr2sxsSXqznyG7dOmizaZMmaLNKlWqpM3MPrZr167VZoGBgdosq7OnZ3myCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAg+PXTUSavf/++9qsW7duls45dOhQbWa2tCGQ1RQtWlSbZaYlVfv27avN6tWrp81at26tzS5cuJCmmoC02Lt3rzZ78cUXLZ2zUKFC2ixnzpzabMSIEdrM7GvECy+8YFddj8PX11ebmdUZHx+vzSZPnpyWkuCCzL72my0fnx6efPJJbXbixAltli9fPm3m7e2dpppcWalSpbSZ2fcKyH62bdumzZo3b67NKleurM22bt2qzY4ePWpfYQ8xW8r+yJEj2mz37t3aLFeuXNqsS5cu2mzQoEHa7JNPPtFm2QVPFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAgWERAAAAAAAADAyLAAAAAAAAYLAppZRdO2aiJaVdhdlSpWbL786YMUOb5c2b11Ithw4d0mZjxozRZt9//72l62V1draNU2Xnni1cuLA2M1tWtFy5cpaud/HiRW22bt06bWa2lKfZPZh9/pn1ev369bXZrVu3tFlWQM86jtlrm4+Pjza7c+eONrt27VpaSsr0vvvuO23Wrl07h1/P3d3d4efMaPTs41m2bJk269WrVwZWkrmYfYysfo5t3rxZm3l7e2uzRo0aWbqemXfffVebTZ06VZt5eHg4vBZ6Fult9+7d2qxu3brazOxzc+jQodrsk08+sa8wF2VPz/JkEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABsevmwjDc889p80WL16cgZWIVKtWTZstX75cm/Xu3Vub/fjjj2mqCUiLnDlzarM+ffpos3Llylm6XkJCgjarV6+eNjt//rw2Gz9+vDYz6y+z5UHNer1Hjx7abOXKldrs7t272gxZ0zvvvKPNzD6PSpQooc2uXLmizQ4cOKDNXGE5ZhGRTz/91NJxrnJ/yNxiYmKcXUK6+uOPP7TZ2bNntZnZUumTJk3SZnfu3NFmBw8e1GZ9+/bVZo0aNdJmZi5fvqzN1qxZo82mTp1q6XqAM+XKlUub+fj4aDOzXod1PFkEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAIDBw9kFuLq2bdtqsyVLljj8elu2bNFmf//9tzYLCAjQZvnz59dmZstp165dW5udOnVKmwGOsHnzZm3WuHFjh1+va9eu2uz8+fOWzmm2HO6MGTO02VtvvaXNnn76aW0WHBxs6Zxt2rTRZufOndNmcF01atTQZjVr1rR0zieffFKbVaxYUZulx9LyZkvsWr1et27dMvR6wIOsvg65CrMeMvt+IDIy0tL1/Pz8tNm0adO0Wb169Sxdz8yJEye02aVLlxx+PWSMggULarNly5ZpM7OfPbOCLl26aLNKlSppM7PXUl5nrePJIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAwMCwCAAAAAACAgWERAAAAAAAADDZl51pyZktWZgU+Pj7abMCAAdps8uTJ2ix37tyWahk8eLA2M1vKPi4uTpstXrxYm/3f//2ffYU95NSpU9ps6NCh2mzDhg2WrtezZ09tduTIEW22b98+S9cz4wpLMGb1nt26das2a9y4saVzmvXzxIkTtVlGfz488cQT2uzatWsOv17Dhg212a+//urw66UHevbxVK5cWZsdPHjQ4dfL6KXls/r1PDw8HH7OjEbPPp6KFStqM7Pvu0qVKpUe5WQaGd17Vp09e1abDR8+XJtt2bJFm/3zzz/aLD2+RmSm96dOZurZRYsWabOBAwdqsyJFimizy5cvp6mmjDJo0CBtZvZ+Mfscs9rr7u7u2iyrs6dnebIIAAAAAAAABoZFAAAAAAAAMDAsAgAAAAAAgIFhEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAACD66+t+hi8vLy0WUhIiDbr1KmTpetdvXpVm82fP99SLbdu3bJUy4gRI7TZnj17tNnChQu1WenSpbXZqlWrtNmVK1e0mZmSJUtqs+7du2uzffv2WboenK9ly5ba7Omnn7Z0zq+//lqbBQUFabPMtCRsq1atHH5Os6WVf//9d4dfD5nb0aNHtdmrr76qzd577z1tVrRoUW2W0Uu9Z/TyyelxvRs3bjj8nHBdf/75pzZr27atNtu+fbs2y5s3b1pKwkOio6O12eDBg7VZeHi4NnviiSe02fXr1+0rDJmO2fecP/zwgzYbOXKkNtu2bVuaanpcTZs21WYDBw7UZmb3bvV78W+++cbSceDJIgAAAAAAADyAYREAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwJCxa9VmgJw5c2ozsyWzO3To4PBavv32W202YcIEh1/PzK1bt7TZsmXLtNlff/2lzUJDQ7VZnjx5tFmuXLm02f79+7WZ2ZLMYWFh2gyuy8fHR5t5enpaOmf37t21mdnSw8uXL9dmx48ft1SLGbP7a9SokcOvd+DAAW12+/Zth18PrmvJkiWWsvbt22szb29vS8eVL19em5lxc9P/W1liYqKlc6bH9Y4dO6bN5s6dm6aakH388ccf2uzNN9/UZvXq1dNmvXv31mZmr90eHq7/o8fNmze1mdn3EV26dNFmZ8+etVSL2etzQECApXMiY4SHh2szs/4y68vIyEhtduXKFW1mtrS8zWbTZpUrV9ZmTZo00WZKKUvXMxMXF6fNxo0bZ+mc4MkiAAAAAAAAPIBhEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAYFNma9c9uKPFZezSg7u7uzYzW0K9Xbt2Dq9l2LBh2uzzzz/XZvHx8Q6vJaM1btxYm5ktD2pm2rRp2sxsyceMZmfbOFVm6lmr/P39tZlZf5UpU8bhtURFRWmzQ4cOOfx6ZkuJt2jRwtI5r127ps1q1qypzawu6ZuZ0LOAa6FnXVfPnj21WalSpSyd09PTU5uNHz9em23dulWbmS1dbubTTz/VZpnpe9WMRs86jtnPUatXr9ZmVpekzwrHVa9eXZsdPXpUm2Vn9vQsTxYBAAAAAADAwLAIAAAAAAAABoZFAAAAAAAAMDAsAgAAAAAAgIFhEQAAAAAAAAwMiwAAAAAAAGCwKTvXOcxMSw2aLZ8ZFxdn6Zw3b97UZtOnT9dms2bN0mZ37961VAsyP5YHdb6CBQtqs5dfflmbTZ48WZt5eXmlqabM7sMPP9Rmo0aNysBKMh49C7gWehZwLfRsxmjatKk2GzNmjDZr06aNNktMTNRmVpeyt3rcxo0btdnUqVO12bZt27QZUmdPz/JkEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAwLAIAAAAAAAABpuyc53DzLTUoKenpzaLi4uzlLVq1Uqb7dy5077CkG2wPKjrat26tTarVauWNps2bZo2c3d3T1NNj2vdunXabMeOHdps7ty52iw+Pj5NNWV29CzgWuhZwLXQs5nbc889p806d+5s6ZxdunTRZkePHtVma9eu1WZm36vCsezpWZ4sAgAAAAAAgIFhEQAAAAAAAAwMiwAAAAAAAGBgWAQAAAAAAAADwyIAAAAAAAAYGBYBAAAAAADAYFN2rnOYnZcaBB7G8qCAa6FnAddCzwKuhZ4FXIs9PcuTRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABgYFgEAAAAAAAAA8MiAAAAAAAAGBgWAQAAAAAAwMCwCAAAAAAAAAaGRQAAAAAAADAwLAIAAAAAAICBYREAAAAAAAAMDIsAAAAAAABgsCmllLOLAAAAAAAAQObAk0UAAAAAAAAwMCwCAAAAAACAgWERAAAAAAAADAyLAAAAAAAAYGBYBAAAAAAAAAPDIgAAAAAAABgYFgEAAAAAAMDAsAgAAAAAAAAGhkUAAAAAAAAw/H+KfUoOH1mZkQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель"
      ],
      "metadata": {
        "id": "IvsYC-qEkrfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Реализуйте VAE архитектуру"
      ],
      "metadata": {
        "id": "LOE45TA1MHl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ODO: РеализуTйте VAE (безусловный)\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_size_flat = 28 * 28\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder_fc1 = nn.Linear(self.img_size_flat, 1024)\n",
        "        self.encoder_mu = nn.Linear(1024, latent_dim)\n",
        "        self.encoder_logvar = nn.Linear(1024, latent_dim)\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder_fc1 = nn.Linear(latent_dim, 1024)\n",
        "        self.decoder_fc2 = nn.Linear(1024, self.img_size_flat)\n",
        "\n",
        "    def encode(self, x):\n",
        "        # Приводим вход к форме (batch_size, 784)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "\n",
        "        # Скрытое представление\n",
        "        hidden = F.relu(self.encoder_fc1(x))\n",
        "\n",
        "        # Параметры распределения\n",
        "        mu = self.encoder_mu(hidden)\n",
        "        logvar = self.encoder_logvar(hidden)\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        # Дисперсия -> стандартное отклонение\n",
        "        sigma = torch.exp(logvar * 0.5)\n",
        "\n",
        "        # Случайный шум\n",
        "        noise = torch.randn_like(sigma)\n",
        "\n",
        "        # Семплирование латентного вектора\n",
        "        z = mu + noise * sigma\n",
        "        return z\n",
        "\n",
        "    def decode(self, z):\n",
        "        # Восстановление изображения из латентного пространства\n",
        "        hidden = F.relu(self.decoder_fc1(z))\n",
        "        x_hat = self.decoder_fc2(hidden)\n",
        "\n",
        "        # Сигмоида и возврат к форме изображения\n",
        "        x_hat = torch.sigmoid(x_hat)\n",
        "        return x_hat.view(-1, 1, 28, 28)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Кодирование\n",
        "        mu, logvar = self.encode(x)\n",
        "\n",
        "        # Репараметризация\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        # Декодирование\n",
        "        reconstructed = self.decode(z)\n",
        "\n",
        "        return reconstructed, mu, logvar\n"
      ],
      "metadata": {
        "id": "UOTAmalSGlHY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss"
      ],
      "metadata": {
        "id": "0P4f4GzioPUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Напишите VAE Loss"
      ],
      "metadata": {
        "id": "fC5Fg_VXFKa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Реализуйте функцию потерь VAE\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    # Денормализуем x обратно в диапазон [0, 1] для BCE\n",
        "    x_denormalized = (x * 0.5) + 0.5\n",
        "\n",
        "    # Потери на реконструкцию: Binary Cross-Entropy, усредненные по элементам и суммированные по батчу\n",
        "    recon_loss = F.binary_cross_entropy(recon_x.view(-1, 28*28), x_denormalized.view(-1, 28*28), reduction='sum')\n",
        "\n",
        "\n",
        "    # KL-дивергенция: 0.5 * sum(1 + logvar - mu^2 - exp(logvar)), усредненная по батчу\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return recon_loss + kl_loss"
      ],
      "metadata": {
        "id": "HP82mY2Pp7iA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тренировка"
      ],
      "metadata": {
        "id": "euSht88Hkt4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Обучите модель на датасете MNIST."
      ],
      "metadata": {
        "id": "JWA7MSUoo4Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 35\n",
        "epochs = 100\n",
        "lr = 1e-3\n",
        "img_size = 28\n",
        "channels = 1\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "zaw-ZH4qo5x3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Обучите модель\n",
        "\n",
        "# Установим устройство (GPU, если доступно, иначе CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используется устройство: {device}\")\n",
        "\n",
        "model = VAE(latent_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Обучение...\n",
        "print(\"Начинается обучение VAE...\")\n",
        "for epoch in range(epochs):\n",
        "    model.train() # Устанавливаем модель в режим обучения\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = vae_loss(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch: {epoch+1}/{epochs}, Average loss: {train_loss / len(train_loader.dataset):.4f}')\n",
        "\n",
        "print(\"Обучение VAE завершено.\")\n",
        ""
      ],
      "metadata": {
        "id": "lDJp84sMp_fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb346187-eb08-4f54-805a-d4815a1306b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используется устройство: cpu\n",
            "Начинается обучение VAE...\n",
            "Epoch: 1/100, Average loss: 149.3864\n",
            "Epoch: 2/100, Average loss: 118.2362\n",
            "Epoch: 3/100, Average loss: 112.8695\n",
            "Epoch: 4/100, Average loss: 110.4641\n",
            "Epoch: 5/100, Average loss: 108.9930\n",
            "Epoch: 6/100, Average loss: 108.0384\n",
            "Epoch: 7/100, Average loss: 107.4125\n",
            "Epoch: 8/100, Average loss: 106.8762\n",
            "Epoch: 9/100, Average loss: 106.3951\n",
            "Epoch: 10/100, Average loss: 106.0279\n",
            "Epoch: 11/100, Average loss: 105.7366\n",
            "Epoch: 12/100, Average loss: 105.5262\n",
            "Epoch: 13/100, Average loss: 105.2689\n",
            "Epoch: 14/100, Average loss: 104.9900\n",
            "Epoch: 15/100, Average loss: 104.8051\n",
            "Epoch: 16/100, Average loss: 104.6025\n",
            "Epoch: 17/100, Average loss: 104.4310\n",
            "Epoch: 18/100, Average loss: 104.2449\n",
            "Epoch: 19/100, Average loss: 104.0343\n",
            "Epoch: 20/100, Average loss: 103.8993\n",
            "Epoch: 21/100, Average loss: 103.7118\n",
            "Epoch: 22/100, Average loss: 103.5779\n",
            "Epoch: 23/100, Average loss: 103.4882\n",
            "Epoch: 24/100, Average loss: 103.3141\n",
            "Epoch: 25/100, Average loss: 103.1738\n",
            "Epoch: 26/100, Average loss: 103.0464\n",
            "Epoch: 27/100, Average loss: 102.9377\n",
            "Epoch: 28/100, Average loss: 102.8695\n",
            "Epoch: 29/100, Average loss: 102.7899\n",
            "Epoch: 30/100, Average loss: 102.6699\n",
            "Epoch: 31/100, Average loss: 102.5781\n",
            "Epoch: 32/100, Average loss: 102.5209\n",
            "Epoch: 33/100, Average loss: 102.3903\n",
            "Epoch: 34/100, Average loss: 102.2700\n",
            "Epoch: 35/100, Average loss: 102.3149\n",
            "Epoch: 36/100, Average loss: 102.1304\n",
            "Epoch: 37/100, Average loss: 102.1030\n",
            "Epoch: 38/100, Average loss: 102.0457\n",
            "Epoch: 39/100, Average loss: 101.9588\n",
            "Epoch: 40/100, Average loss: 101.8501\n",
            "Epoch: 41/100, Average loss: 101.8871\n",
            "Epoch: 42/100, Average loss: 101.7538\n",
            "Epoch: 43/100, Average loss: 101.6982\n",
            "Epoch: 44/100, Average loss: 101.6344\n",
            "Epoch: 45/100, Average loss: 101.6051\n",
            "Epoch: 46/100, Average loss: 101.5199\n",
            "Epoch: 47/100, Average loss: 101.5564\n",
            "Epoch: 48/100, Average loss: 101.4831\n",
            "Epoch: 49/100, Average loss: 101.3674\n",
            "Epoch: 50/100, Average loss: 101.3148\n",
            "Epoch: 51/100, Average loss: 101.2363\n",
            "Epoch: 52/100, Average loss: 101.2277\n",
            "Epoch: 53/100, Average loss: 101.2433\n",
            "Epoch: 54/100, Average loss: 101.1675\n",
            "Epoch: 55/100, Average loss: 101.1305\n",
            "Epoch: 56/100, Average loss: 101.0470\n",
            "Epoch: 57/100, Average loss: 101.0088\n",
            "Epoch: 58/100, Average loss: 100.9971\n",
            "Epoch: 59/100, Average loss: 100.9937\n",
            "Epoch: 60/100, Average loss: 100.8703\n",
            "Epoch: 61/100, Average loss: 100.8937\n",
            "Epoch: 62/100, Average loss: 100.8999\n",
            "Epoch: 63/100, Average loss: 100.7865\n",
            "Epoch: 64/100, Average loss: 100.7432\n",
            "Epoch: 65/100, Average loss: 100.7223\n",
            "Epoch: 66/100, Average loss: 100.7301\n",
            "Epoch: 67/100, Average loss: 100.6485\n",
            "Epoch: 68/100, Average loss: 100.7323\n",
            "Epoch: 69/100, Average loss: 100.5622\n",
            "Epoch: 70/100, Average loss: 100.6085\n",
            "Epoch: 71/100, Average loss: 100.5720\n",
            "Epoch: 72/100, Average loss: 100.5910\n",
            "Epoch: 73/100, Average loss: 100.4956\n",
            "Epoch: 74/100, Average loss: 100.4125\n",
            "Epoch: 75/100, Average loss: 100.5153\n",
            "Epoch: 76/100, Average loss: 100.3755\n",
            "Epoch: 77/100, Average loss: 100.3960\n",
            "Epoch: 78/100, Average loss: 100.3945\n",
            "Epoch: 79/100, Average loss: 100.3274\n",
            "Epoch: 80/100, Average loss: 100.2820\n",
            "Epoch: 81/100, Average loss: 100.2469\n",
            "Epoch: 82/100, Average loss: 100.2699\n",
            "Epoch: 83/100, Average loss: 100.2272\n",
            "Epoch: 84/100, Average loss: 100.2247\n",
            "Epoch: 85/100, Average loss: 100.1708\n",
            "Epoch: 86/100, Average loss: 100.1937\n",
            "Epoch: 87/100, Average loss: 100.0984\n",
            "Epoch: 88/100, Average loss: 100.1647\n",
            "Epoch: 89/100, Average loss: 100.1004\n",
            "Epoch: 90/100, Average loss: 100.0860\n",
            "Epoch: 91/100, Average loss: 100.0842\n",
            "Epoch: 92/100, Average loss: 100.0499\n",
            "Epoch: 93/100, Average loss: 100.0232\n",
            "Epoch: 94/100, Average loss: 100.0203\n",
            "Epoch: 95/100, Average loss: 99.9848\n",
            "Epoch: 96/100, Average loss: 99.9311\n",
            "Epoch: 97/100, Average loss: 100.0166\n",
            "Epoch: 98/100, Average loss: 99.9197\n",
            "Epoch: 99/100, Average loss: 99.9120\n",
            "Epoch: 100/100, Average loss: 99.9196\n",
            "Обучение VAE завершено.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метрика"
      ],
      "metadata": {
        "id": "OqKZRnxnk2ON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом разделе вам необходимо посчитать метрику FID."
      ],
      "metadata": {
        "id": "Jm1SCUUjk42O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Что такое FID?**\n",
        "\n",
        "**FID (Fréchet Inception Distance)** — это метрика качества генеративных моделей для изображений, которая измеряет **расстояние между распределениями признаков реальных и сгенерированных изображений** в пространстве предобученной нейросети (обычно Inception-v3).\n",
        "\n",
        "Чем **ниже FID**, тем **ближе** сгенерированные изображения к реальным — как по **качеству**, так и по **разнообразию**.\n",
        "\n",
        "Формула FID основана на предположении, что признаки в этом пространстве приблизительно распределены как **многомерное нормальное распределение**:\n",
        "\n",
        "$$\n",
        "\\text{FID} = \\|\\mu_r - \\mu_g\\|^2 + \\mathrm{Tr}\\left( \\Sigma_r + \\Sigma_g - 2\\sqrt{\\Sigma_r \\Sigma_g} \\right)\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $(\\mu_r, \\Sigma_r)$ — среднее и ковариационная матрица признаков **реальных** изображений,\n",
        "- $(\\mu_g, \\Sigma_g)$ — то же для **сгенерированных** изображений,\n",
        "- $\\mathrm{Tr}(\\cdot)$ — след матрицы.\n",
        "\n",
        "> 🔹 FID = 0 означает полное совпадение распределений.  \n",
        "> 🔹 Чем выше FID ↑ , тем качество или разнообразие генерации ниже ↓."
      ],
      "metadata": {
        "id": "Weiu7gOmk_TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Как считать FID на MNIST?**\n",
        "\n",
        "Вычислите FID с помощью библиотеки [`pytorch-fid`](https://github.com/mseitzer/pytorch-fid):\n",
        "\n",
        "```bash\n",
        "python -m pytorch_fid real_mnist/ fake_mnist/ --device cuda\n",
        "```\n",
        "\n",
        "> **Важно**: несмотря на то, что признаки Inception-v3 не оптимальны для рукописных цифр, FID остаётся полезной **относительной метрикой** — она позволяет сравнивать разные модели между собой при одинаковых условиях предобработки.\n"
      ],
      "metadata": {
        "id": "TKKlXLdNlCGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание:** Сгенерируйте и сохраните 10 тыс. изображений, выберите 10 тыс. реальных изображений из MNIST тестовой выборки и посчитайте FID между реальными и сгенерированными изображениями."
      ],
      "metadata": {
        "id": "qI93gAkQEg7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Сгенерируйте и сохраните 10 тыс. изображений для FID в папке mnist_vae_fake\n",
        "# Каталог для сохранения сгенерированных изображений\n",
        "fake_images_dir = 'mnist_vae_fake'\n",
        "os.makedirs(fake_images_dir, exist_ok=True)\n",
        "\n",
        "num_images_to_generate = 10000\n",
        "saved_count_fake = 0\n",
        "\n",
        "# Переключаем модель в режим инференса\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    idx = 0\n",
        "    while idx < num_images_to_generate:\n",
        "        # Сэмплируем точку из латентного пространства\n",
        "        z = torch.randn(1, latent_dim, device=device)\n",
        "\n",
        "        # Получаем изображение из декодера\n",
        "        output = model.decode(z)\n",
        "        output = output.detach().cpu()\n",
        "\n",
        "        # Приводим изображение к диапазону [0, 1]\n",
        "        img = output[0] * 0.5 + 0.5\n",
        "\n",
        "        # Конвертация в PIL и сохранение\n",
        "        pil_img = transforms.ToPILImage()(img)\n",
        "        file_name = f'fake_mnist_{idx}.png'\n",
        "        pil_img.save(os.path.join(fake_images_dir, file_name))\n",
        "\n",
        "        saved_count_fake += 1\n",
        "        idx += 1\n",
        "\n",
        "print(\n",
        "    f\"Сгенерировано и сохранено {saved_count_fake} \"\n",
        "    f\"фейковых изображений MNIST в папку '{fake_images_dir}'\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "mqM9FD1rqEEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3e951d-1446-4d82-986f-1f64ee9c7e97"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сгенерировано и сохранено 10000 фейковых изображений MNIST в папку 'mnist_vae_fake'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтобы вычислить FID, запустите в терминале:\n",
        "!pip install pytorch-fid\n",
        "!python -m pytorch_fid mnist_vae_real mnist_vae_fake --device cpu"
      ],
      "metadata": {
        "id": "UzL3USg_riUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "384da7b5-41b2-4b5e-d9ac-9aab32e0674f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.12/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n",
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:00<00:00, 197MB/s]\n",
            "100% 200/200 [57:01<00:00, 17.11s/it]\n",
            "100% 200/200 [58:38<00:00, 17.59s/it]\n",
            "FID:  45.42977252628765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **II Часть. Conditional VAE (6 баллов)**\n"
      ],
      "metadata": {
        "id": "rw-YrISFHgnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы уже научились обучать обычный VAE на датасете картинок и получать новые картинки. Давайте теперь научимся обучать модель, которая сможет генерировать не просто рандомную картинку, которая похожа на картинки из датасета, а картинку из конкретного класса. Например, в MNIST датасете 10 классов (от 1 до 10) и мы хотим говорить модели \"Сгенерируй мне только конкретно картинку с числом 3.\" и она должна теперь уже сгенерировать только картинку с числом 3. Как раз Conditional VAE это должен уметь делать и генерировать картинку, обуславливаясь на конкретный класс.\n",
        "\n",
        "\n",
        "**Задание**. В этой части домашнего задания вам предстоит обучить Conditional VAE на MNIST. Это значит, что модель на вход должна принимать картинку и класс картинки.\n",
        "\n",
        "**Метрика**. Вам нужно сгенерировать 1000 сэмплов на каждый класс и посчитать FID для каждого класса."
      ],
      "metadata": {
        "id": "OVMf6pBnHd8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Conditional Variational Autoencoder (CVAE)\n",
        "# Условие (класс) подается как one-hot вектор и используется\n",
        "# как в encoder, так и в decoder\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes=10):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.img_size_flat = 28 * 28\n",
        "\n",
        "        # ---------- Encoder ----------\n",
        "        # Вход: [x_flat, c]\n",
        "        # x_flat — изображение, развернутое в вектор (784)\n",
        "        # c       — one-hot вектор класса (num_classes)\n",
        "        self.encoder_fc1 = nn.Linear(self.img_size_flat + self.num_classes, 1024)\n",
        "        self.encoder_mu = nn.Linear(1024, latent_dim)\n",
        "        self.encoder_logvar = nn.Linear(1024, latent_dim)\n",
        "\n",
        "        # ---------- Decoder ----------\n",
        "        # Вход: [z, c]\n",
        "        # z — латентный вектор\n",
        "        # c — one-hot вектор класса\n",
        "        self.decoder_fc1 = nn.Linear(latent_dim + self.num_classes, 1024)\n",
        "        self.decoder_fc2 = nn.Linear(1024, self.img_size_flat)\n",
        "\n",
        "    def encode(self, x, c):\n",
        "        \"\"\"\n",
        "        Кодировщик: получает изображение и класс,\n",
        "        возвращает параметры распределения q(z|x,c)\n",
        "        \"\"\"\n",
        "        # Преобразуем изображение в плоский вектор\n",
        "        x_flat = x.view(-1, self.img_size_flat)\n",
        "\n",
        "        # Объединяем изображение и условие (класс)\n",
        "        enc_input = torch.cat([x_flat, c], dim=1)\n",
        "\n",
        "        h = F.relu(self.encoder_fc1(enc_input))\n",
        "        mu = self.encoder_mu(h)\n",
        "        logvar = self.encoder_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"\n",
        "        Репараметризация:\n",
        "        z = mu + eps * sigma, где eps ~ N(0, I)\n",
        "        \"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, c):\n",
        "        \"\"\"\n",
        "        Декодировщик: восстанавливает изображение\n",
        "        по латентному вектору и классу\n",
        "        \"\"\"\n",
        "        # Объединяем латентный вектор и условие\n",
        "        dec_input = torch.cat([z, c], dim=1)\n",
        "\n",
        "        h = F.relu(self.decoder_fc1(dec_input))\n",
        "        # Sigmoid — так как значения пикселей в [0, 1]\n",
        "        return torch.sigmoid(self.decoder_fc2(h))\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        \"\"\"\n",
        "        Полный проход CVAE:\n",
        "        x, c → encoder → z → decoder → x_recon\n",
        "        \"\"\"\n",
        "        mu, logvar = self.encode(x, c)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon_x = self.decode(z, c)\n",
        "        return recon_x, mu, logvar\n"
      ],
      "metadata": {
        "id": "YWFKXSxOJtwS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Обучите CVAE\n",
        "\n",
        "# ---------- Гиперпараметры CVAE ----------\n",
        "cvae_latent_dim = 35      # Размер латентного пространства\n",
        "cvae_epochs = 100         # Количество эпох обучения\n",
        "cvae_lr = 1e-3            # Скорость обучения\n",
        "num_classes = 10          # Число классов (MNIST)\n",
        "\n",
        "# ---------- Устройство ----------\n",
        "# Используем GPU, если доступен, иначе CPU\n",
        "cvae_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"CVAE используется устройство: {cvae_device}\")\n",
        "\n",
        "# ---------- Модель и оптимизатор ----------\n",
        "cvae_model = CVAE(cvae_latent_dim, num_classes).to(cvae_device)\n",
        "cvae_optimizer = optim.Adam(cvae_model.parameters(), lr=cvae_lr)\n",
        "\n",
        "# ---------- Обучение CVAE ----------\n",
        "print(\"Начинается обучение CVAE...\")\n",
        "for epoch in range(cvae_epochs):\n",
        "    cvae_model.train()  # Переключаем модель в режим обучения\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        # Переносим данные и метки на устройство\n",
        "        data = data.to(cvae_device)\n",
        "        labels = labels.to(cvae_device)\n",
        "\n",
        "        # One-hot кодирование меток классов\n",
        "        # (batch_size, num_classes)\n",
        "        one_hot_labels = F.one_hot(labels, num_classes=num_classes).float()\n",
        "\n",
        "        # Обнуляем градиенты перед шагом оптимизации\n",
        "        cvae_optimizer.zero_grad()\n",
        "\n",
        "        # Прямой проход\n",
        "        recon_batch, mu, logvar = cvae_model(data, one_hot_labels)\n",
        "\n",
        "        # Функция потерь (reconstruction + KL)\n",
        "        # Та же, что и для обычного VAE\n",
        "        loss = vae_loss(recon_batch, data, mu, logvar)\n",
        "\n",
        "        # Обратное распространение ошибки\n",
        "        loss.backward()\n",
        "        cvae_optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Средний лосс на один элемент датасета\n",
        "    avg_loss = train_loss / len(train_loader.dataset)\n",
        "    print(f'CVAE Epoch: {epoch + 1}/{cvae_epochs}, Average loss: {avg_loss:.4f}')\n",
        "\n",
        "print(\"Обучение CVAE завершено.\")\n"
      ],
      "metadata": {
        "id": "x5KuxfgDtPCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f73aa16e-2268-47fa-f6ac-c12359472d99"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CVAE используется устройство: cpu\n",
            "Начинается обучение CVAE...\n",
            "CVAE Epoch: 1/100, Average loss: 146.7381\n",
            "CVAE Epoch: 2/100, Average loss: 115.9522\n",
            "CVAE Epoch: 3/100, Average loss: 110.1441\n",
            "CVAE Epoch: 4/100, Average loss: 107.4095\n",
            "CVAE Epoch: 5/100, Average loss: 105.8019\n",
            "CVAE Epoch: 6/100, Average loss: 104.6746\n",
            "CVAE Epoch: 7/100, Average loss: 103.7549\n",
            "CVAE Epoch: 8/100, Average loss: 103.1080\n",
            "CVAE Epoch: 9/100, Average loss: 102.5276\n",
            "CVAE Epoch: 10/100, Average loss: 102.0760\n",
            "CVAE Epoch: 11/100, Average loss: 101.6540\n",
            "CVAE Epoch: 12/100, Average loss: 101.2538\n",
            "CVAE Epoch: 13/100, Average loss: 100.9665\n",
            "CVAE Epoch: 14/100, Average loss: 100.6928\n",
            "CVAE Epoch: 15/100, Average loss: 100.4989\n",
            "CVAE Epoch: 16/100, Average loss: 100.1519\n",
            "CVAE Epoch: 17/100, Average loss: 100.0057\n",
            "CVAE Epoch: 18/100, Average loss: 99.7106\n",
            "CVAE Epoch: 19/100, Average loss: 99.5829\n",
            "CVAE Epoch: 20/100, Average loss: 99.3785\n",
            "CVAE Epoch: 21/100, Average loss: 99.2606\n",
            "CVAE Epoch: 22/100, Average loss: 99.0614\n",
            "CVAE Epoch: 23/100, Average loss: 98.9149\n",
            "CVAE Epoch: 24/100, Average loss: 98.7419\n",
            "CVAE Epoch: 25/100, Average loss: 98.5825\n",
            "CVAE Epoch: 26/100, Average loss: 98.4848\n",
            "CVAE Epoch: 27/100, Average loss: 98.3604\n",
            "CVAE Epoch: 28/100, Average loss: 98.1930\n",
            "CVAE Epoch: 29/100, Average loss: 98.0912\n",
            "CVAE Epoch: 30/100, Average loss: 98.0364\n",
            "CVAE Epoch: 31/100, Average loss: 97.9196\n",
            "CVAE Epoch: 32/100, Average loss: 97.8107\n",
            "CVAE Epoch: 33/100, Average loss: 97.7172\n",
            "CVAE Epoch: 34/100, Average loss: 97.6945\n",
            "CVAE Epoch: 35/100, Average loss: 97.5497\n",
            "CVAE Epoch: 36/100, Average loss: 97.4979\n",
            "CVAE Epoch: 37/100, Average loss: 97.3726\n",
            "CVAE Epoch: 38/100, Average loss: 97.2944\n",
            "CVAE Epoch: 39/100, Average loss: 97.2591\n",
            "CVAE Epoch: 40/100, Average loss: 97.1684\n",
            "CVAE Epoch: 41/100, Average loss: 97.1026\n",
            "CVAE Epoch: 42/100, Average loss: 97.0498\n",
            "CVAE Epoch: 43/100, Average loss: 96.9448\n",
            "CVAE Epoch: 44/100, Average loss: 96.9040\n",
            "CVAE Epoch: 45/100, Average loss: 96.8847\n",
            "CVAE Epoch: 46/100, Average loss: 96.7824\n",
            "CVAE Epoch: 47/100, Average loss: 96.7064\n",
            "CVAE Epoch: 48/100, Average loss: 96.6859\n",
            "CVAE Epoch: 49/100, Average loss: 96.6288\n",
            "CVAE Epoch: 50/100, Average loss: 96.5175\n",
            "CVAE Epoch: 51/100, Average loss: 96.5276\n",
            "CVAE Epoch: 52/100, Average loss: 96.4788\n",
            "CVAE Epoch: 53/100, Average loss: 96.3936\n",
            "CVAE Epoch: 54/100, Average loss: 96.4245\n",
            "CVAE Epoch: 55/100, Average loss: 96.3185\n",
            "CVAE Epoch: 56/100, Average loss: 96.2768\n",
            "CVAE Epoch: 57/100, Average loss: 96.2524\n",
            "CVAE Epoch: 58/100, Average loss: 96.2094\n",
            "CVAE Epoch: 59/100, Average loss: 96.1276\n",
            "CVAE Epoch: 60/100, Average loss: 96.0889\n",
            "CVAE Epoch: 61/100, Average loss: 96.0788\n",
            "CVAE Epoch: 62/100, Average loss: 96.0340\n",
            "CVAE Epoch: 63/100, Average loss: 95.9777\n",
            "CVAE Epoch: 64/100, Average loss: 95.9956\n",
            "CVAE Epoch: 65/100, Average loss: 95.8956\n",
            "CVAE Epoch: 66/100, Average loss: 95.8904\n",
            "CVAE Epoch: 67/100, Average loss: 95.8936\n",
            "CVAE Epoch: 68/100, Average loss: 95.8356\n",
            "CVAE Epoch: 69/100, Average loss: 95.7530\n",
            "CVAE Epoch: 70/100, Average loss: 95.7288\n",
            "CVAE Epoch: 71/100, Average loss: 95.7027\n",
            "CVAE Epoch: 72/100, Average loss: 95.7022\n",
            "CVAE Epoch: 73/100, Average loss: 95.6675\n",
            "CVAE Epoch: 74/100, Average loss: 95.5918\n",
            "CVAE Epoch: 75/100, Average loss: 95.6135\n",
            "CVAE Epoch: 76/100, Average loss: 95.5044\n",
            "CVAE Epoch: 77/100, Average loss: 95.4967\n",
            "CVAE Epoch: 78/100, Average loss: 95.4584\n",
            "CVAE Epoch: 79/100, Average loss: 95.4550\n",
            "CVAE Epoch: 80/100, Average loss: 95.4582\n",
            "CVAE Epoch: 81/100, Average loss: 95.3673\n",
            "CVAE Epoch: 82/100, Average loss: 95.4096\n",
            "CVAE Epoch: 83/100, Average loss: 95.3115\n",
            "CVAE Epoch: 84/100, Average loss: 95.3384\n",
            "CVAE Epoch: 85/100, Average loss: 95.2825\n",
            "CVAE Epoch: 86/100, Average loss: 95.2792\n",
            "CVAE Epoch: 87/100, Average loss: 95.2397\n",
            "CVAE Epoch: 88/100, Average loss: 95.2363\n",
            "CVAE Epoch: 89/100, Average loss: 95.2063\n",
            "CVAE Epoch: 90/100, Average loss: 95.1972\n",
            "CVAE Epoch: 91/100, Average loss: 95.1603\n",
            "CVAE Epoch: 92/100, Average loss: 95.1190\n",
            "CVAE Epoch: 93/100, Average loss: 95.0914\n",
            "CVAE Epoch: 94/100, Average loss: 95.1239\n",
            "CVAE Epoch: 95/100, Average loss: 95.0585\n",
            "CVAE Epoch: 96/100, Average loss: 94.9903\n",
            "CVAE Epoch: 97/100, Average loss: 95.0022\n",
            "CVAE Epoch: 98/100, Average loss: 94.9300\n",
            "CVAE Epoch: 99/100, Average loss: 95.0166\n",
            "CVAE Epoch: 100/100, Average loss: 94.9119\n",
            "Обучение CVAE завершено.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "fake_per_class_dir = 'fake_per_class'\n",
        "real_per_class_dir = 'real_per_class'\n",
        "\n",
        "os.makedirs(fake_per_class_dir, exist_ok=True)\n",
        "os.makedirs(real_per_class_dir, exist_ok=True)\n",
        "\n",
        "num_samples_per_class = 1000\n",
        "\n",
        "cvae_model.eval()\n",
        "\n",
        "# --------------------------------------------------\n",
        "# КРИТИЧНО: правильная размерность latent z\n",
        "# decoder ожидает z_dim + num_classes = 45\n",
        "# --------------------------------------------------\n",
        "latent_dim = 45 - num_classes  # = 35\n",
        "\n",
        "print(f\"Используем latent_dim={latent_dim}, num_classes={num_classes}\")\n",
        "\n",
        "# ==================================================\n",
        "# 1. Генерация изображений\n",
        "# ==================================================\n",
        "print(\"Генерация изображений для каждого класса...\")\n",
        "with torch.no_grad():\n",
        "    for c in range(num_classes):\n",
        "        class_fake_dir = os.path.join(fake_per_class_dir, f'class_{c}')\n",
        "        os.makedirs(class_fake_dir, exist_ok=True)\n",
        "\n",
        "        # one-hot класс\n",
        "        class_one_hot = torch.zeros(1, num_classes, device=cvae_device)\n",
        "        class_one_hot[0, c] = 1\n",
        "\n",
        "        for i in range(num_samples_per_class):\n",
        "            # z правильной размерности\n",
        "            z = torch.randn(1, latent_dim, device=cvae_device)\n",
        "\n",
        "            # decode(z, c) — как и требует твоя модель\n",
        "            generated_image = cvae_model.decode(z, class_one_hot).cpu()\n",
        "\n",
        "            # [-1,1] → [0,1]\n",
        "            img = generated_image.view(1, 28, 28)\n",
        "            img = img * 0.5 + 0.5\n",
        "            img = transforms.ToPILImage()(img.squeeze(0))\n",
        "\n",
        "            img.save(\n",
        "                os.path.join(\n",
        "                    class_fake_dir,\n",
        "                    f'fake_mnist_class_{c}_{i}.png'\n",
        "                )\n",
        "            )\n",
        "\n",
        "print(\"Генерация завершена.\")\n",
        "\n",
        "# ==================================================\n",
        "# 2. Сохранение реальных изображений\n",
        "# ==================================================\n",
        "print(\"Сохранение реальных изображений для каждого класса...\")\n",
        "real_counts_per_class = {i: 0 for i in range(num_classes)}\n",
        "\n",
        "for img, label in test_dataset:\n",
        "    if real_counts_per_class[label] < num_samples_per_class:\n",
        "        class_real_dir = os.path.join(real_per_class_dir, f'class_{label}')\n",
        "        os.makedirs(class_real_dir, exist_ok=True)\n",
        "\n",
        "        img_to_save = img * 0.5 + 0.5\n",
        "        img_to_save = transforms.ToPILImage()(img_to_save.squeeze(0))\n",
        "\n",
        "        img_to_save.save(\n",
        "            os.path.join(\n",
        "                class_real_dir,\n",
        "                f'real_mnist_class_{label}_{real_counts_per_class[label]}.png'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        real_counts_per_class[label] += 1\n",
        "\n",
        "    if all(v == num_samples_per_class for v in real_counts_per_class.values()):\n",
        "        break\n",
        "\n",
        "print(\"Сохранение реальных изображений завершено.\")\n"
      ],
      "metadata": {
        "id": "0cUAD7Fejo0u",
        "outputId": "bac861f8-3dfb-4e48-ba95-f9753f763be0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используем latent_dim=35, num_classes=10\n",
            "Генерация изображений для каждого класса...\n",
            "Генерация завершена.\n",
            "Сохранение реальных изображений для каждого класса...\n",
            "Сохранение реальных изображений завершено.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Посчитайте FID для каждого класса между сгенерированными и реальными изображениями\n"
      ],
      "metadata": {
        "id": "PJSeXhiVxz_G"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from pytorch_fid import fid_score\n",
        "\n",
        "# -------------------------------\n",
        "# Настройки\n",
        "# -------------------------------\n",
        "real_root = 'real_per_class'\n",
        "fake_root = 'fake_per_class'\n",
        "\n",
        "num_classes = 10\n",
        "batch_size = 128\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "fid_per_class = {}\n",
        "\n",
        "# -------------------------------\n",
        "# Подсчёт FID по классам\n",
        "# -------------------------------\n",
        "print(\"Подсчёт FID по классам (MNIST-correct)...\\n\")\n",
        "\n",
        "for class_id in range(num_classes):\n",
        "    real_dir = os.path.join(real_root, f'class_{class_id}')\n",
        "    fake_dir = os.path.join(fake_root, f'class_{class_id}')\n",
        "\n",
        "    if not os.path.isdir(real_dir):\n",
        "        raise FileNotFoundError(f\"Не найдена папка с реальными изображениями: {real_dir}\")\n",
        "    if not os.path.isdir(fake_dir):\n",
        "        raise FileNotFoundError(f\"Не найдена папка с сгенерированными изображениями: {fake_dir}\")\n",
        "\n",
        "    fid_value = fid_score.calculate_fid_given_paths(\n",
        "        paths=[real_dir, fake_dir],\n",
        "        batch_size=batch_size,\n",
        "        device=device,\n",
        "        dims=2048\n",
        "    )\n",
        "\n",
        "    fid_per_class[class_id] = fid_value\n",
        "    print(f\"FID для класса {class_id}: {fid_value:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Средний FID\n",
        "# -------------------------------\n",
        "mean_fid = sum(fid_per_class.values()) / num_classes\n",
        "\n",
        "print(\"\\n===============================\")\n",
        "print(f\"Средний FID по классам: {mean_fid:.4f}\")\n",
        "print(\"===============================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-3_LVvPeWle",
        "outputId": "8287f503-715b-4865-c264-1cf190a91c58"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Подсчёт FID по классам (MNIST-correct)...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [05:38<00:00, 16.92s/it]\n",
            "100%|██████████| 20/20 [05:58<00:00, 17.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID для класса 0: 66.6585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [05:35<00:00, 16.79s/it]\n",
            "100%|██████████| 20/20 [06:00<00:00, 18.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID для класса 1: 47.7352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [05:44<00:00, 17.24s/it]\n",
            "100%|██████████| 20/20 [05:49<00:00, 17.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID для класса 2: 57.0846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [05:32<00:00, 16.60s/it]\n",
            "100%|██████████| 20/20 [05:56<00:00, 17.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID для класса 3: 53.5098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [05:36<00:00, 16.81s/it]\n",
            "100%|██████████| 20/20 [05:55<00:00, 17.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID для класса 4: 47.3736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [05:09<00:00, 17.17s/it]\n",
            "100%|██████████| 20/20 [05:58<00:00, 17.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID для класса 5: 52.5251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [05:25<00:00, 16.28s/it]\n",
            "100%|██████████| 20/20 [05:53<00:00, 17.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID для класса 6: 58.0574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [05:50<00:00, 17.51s/it]\n",
            "100%|██████████| 20/20 [05:53<00:00, 17.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID для класса 7: 48.3626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [05:32<00:00, 16.63s/it]\n",
            "100%|██████████| 20/20 [05:53<00:00, 17.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID для класса 8: 54.6913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [05:52<00:00, 17.61s/it]\n",
            "100%|██████████| 20/20 [06:06<00:00, 18.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID для класса 9: 49.6083\n",
            "\n",
            "===============================\n",
            "Средний FID по классам: 53.5606\n",
            "===============================\n"
          ]
        }
      ]
    }
  ]
}